<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  
  
  <meta name="generator" content="Wowchemy 4.8.0 for Hugo">
  

  

  
  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Julien Vitay">

  
  
  
    
  
  <meta name="description" content="Deep neural networks and their applications to emotion recognition, attention, sensor fusion...">

  
  <link rel="alternate" hreflang="en-us" href="https://julien-vitay.net/project/deeplearning/">

  







  




  
  
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  

  
  
  
  <meta name="theme-color" content="#6A8A26">
  

  
  

  
  
  
  
    
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha256-FMvZuGapsJLjouA6k7Eo2lusoAX9i0ShlWFG6qt7SLc=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-light">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/styles/github.min.css" crossorigin="anonymous" title="hl-dark" disabled>
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.css" integrity="sha512-1xoFisiGdy9nvho8EgXuXvnpR5GAMSjFwp40gSRE3NwdUdIMIKuPa7bqoUhLD0O/5tPNhteAsE5XyyMi5reQVA==" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.2.2/lazysizes.min.js" integrity="sha512-TmDwFLhg3UA4ZG0Eb4MIyT1O1Mb+Oww5kFG0uHqXsdbyZz9DcvYQhKpGgNkamAI6h2lGGZq2X8ftOJvF/XjTUg==" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      
        
      

      
    
      

      
      

      
    
      

      
      

      
    

  

  
  
  
    
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
    
  

  
  
  
  
  <link rel="stylesheet" href="/css/wowchemy.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png">

  <link rel="canonical" href="https://julien-vitay.net/project/deeplearning/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="og:site_name" content="Julien Vitay">
  <meta property="og:url" content="https://julien-vitay.net/project/deeplearning/">
  <meta property="og:title" content="Deep Learning | Julien Vitay">
  <meta property="og:description" content="Deep neural networks and their applications to emotion recognition, attention, sensor fusion..."><meta property="og:image" content="https://julien-vitay.net/project/deeplearning/featured.png">
  <meta property="twitter:image" content="https://julien-vitay.net/project/deeplearning/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2020-10-20T00:00:00&#43;00:00">
    
    <meta property="article:modified_time" content="2020-10-20T00:00:00&#43;00:00">
  

  


    









<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://julien-vitay.net/project/deeplearning/"
  },
  "headline": "Deep Learning",
  
  "image": [
    "https://julien-vitay.net/project/deeplearning/featured.png"
  ],
  
  "datePublished": "2020-10-20T00:00:00Z",
  "dateModified": "2020-10-20T00:00:00Z",
  
  "author": {
    "@type": "Person",
    "name": "Julien Vitay"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Julien Vitay",
    "logo": {
      "@type": "ImageObject",
      "url": "https://julien-vitay.net/images/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_192x192_fill_lanczos_center_3.png"
    }
  },
  "description": "Deep neural networks and their applications to emotion recognition, attention, sensor fusion..."
}
</script>

  

  


  


  





  <title>Deep Learning | Julien Vitay</title>

</head>


<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" class=" ">

  
  
  
  
    <script>const isSiteThemeDark = false;</script>
  
  
  <script src="/js/load-theme.js"></script>

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search" class="form-control">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  












<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Julien Vitay</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Julien Vitay</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-end" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#projects"><span>Research</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/publication"><span>Publications</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#teaching"><span>Teaching</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Blog</span></a>
        </li>

        
        

        

        
        
        
          
        

        

        
        
        
        

        
          
            
            
          
          
            
            
            
              
            
            
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#contact"><span>Contact</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      
      
      <li class="nav-item">
        <a class="nav-link js-search" href="#" aria-label="Search"><i class="fas fa-search" aria-hidden="true"></i></a>
      </li>
      

      
      

      

    </ul>

  </div>
</nav>



  <article class="article article-project">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Deep Learning</h1>

  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    2020
  </span>
  

  

  

  
  
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <p>The recent hype on <strong>deep learning</strong> has revived the interest for artificial neural networks and their applications. I am involved in the co-supervision of PhD students working on this topic, but do not do active research on it.</p>
<!--
Here are some projects done lately.

## Project 1 : Facial emotion recognition

Facial expression recognition is an important research field in computer vision. Although detecting facial features is an easy task for a human, computers still have a hard time doing it. Factors such as interpersonal variation (gender, skin color), intrapersonal variation (pose, expression) and different recording conditions (image resolution, lighting) add to the complexity of the problem. This is particularly relevant in the context of emotion recognition, where systems should be able to automatically recognize in which emotional state humans are.

On human faces, emotional expression heavily relies on the activation of individual facial muscles. A classical approach to describe facial expressions at the muscular level is the Facial Action Coding System (FACS) proposed by Ekman (1978). In this framework, movement of specific facial regions are described as Actions Units (AU), which basically describe deviations from a neutral expression. AUs are specific to facial regions (corner of the mouth or the eye, etc.). Although there are 69 AUs in the FACS theory, 28 of them are mostly useful for emotion recognition. We have focused on 12 of them: 1 (Inner Brow Raiser), 2 (Outer Brow Raiser), 4 (Brow Lowerer), 6 (Cheek Raiser), 7 (Lid Tightener), 10 (Upper Lip Raiser), 12 (Lip Corner Puller), 14 (Dimpler), 15 (Lip Corner Depressor), 17 (Chin Raiser), 23 (Lip Tightener), 24 (Lip Pressor).

There are different training sets generally available to the community containing various number of FACS-annotated images, with different numbers of annotated AUs: CCK+, MMI, UNBC-McMaster PAIN, DUSFA, BP4D, SEMAINE, etc. The 12 selected AUs correspond to the annotated AUs in BP4D, which is the most massive dataset. The main interest of these AUs is that they are mostly sufficient to predict the occurence of the 6 basic emotions using the EMFACS correspondance table:

| Emotion   |  Action Units     |
| --------  |  ---------------  |
| Happiness |  6, 12            |
| Sadness   |  1, 4, 15         |
| Surprise  |  1, 2, 5B, 26     |
| Fear      |  1, 2, 4, 5, 7, 20, 26 |
| Anger     |  4, 5, 7, 23      |
| Disgust   |  9, 15, 16        |

After investigating various architectures to automatically predict AU occurence on faces, we converged towards a neural network architecture inspired from VGG-16:







  



  
  











<figure id="figure-convolutional-neural-network-for-facs-recognition">


  <a data-fancybox="" href="/project/deeplearning/model_hufd6724ac2b696e61ce0911e529a47b91_57163_2000x2000_fit_lanczos_3.png" data-caption="Convolutional Neural Network for FACS recognition.">


  <img data-src="/project/deeplearning/model_hufd6724ac2b696e61ce0911e529a47b91_57163_2000x2000_fit_lanczos_3.png" class="lazyload" alt="" width="1350" height="339">
</a>


  
  
  <figcaption data-pre="Figure " data-post=":" class="numbered">
    Convolutional Neural Network for FACS recognition.
  </figcaption>


</figure>


It consists of 4 convolutional blocks, each composed of 2 convolutional layers (kernel size 3x3, ReLU activation function) and a max-pooling layers (2x2). A dropout layer with p=0.2 is added after the max-pooling. After 4 such convolutional blocks with increasing numbers of features (32, 64, 126 and 256), the last tensor (6x6x256) is flattened into a vector of 9216 elements and projected on a fully connected layer of 500 neurons. The output layer has 12 neurons using the sigmoid activation function, each representing one of the 12 AUs present in the combined dataset. The network has a total of 5.786.192 trainable parameters (weights and biases), what makes it a middle-sized deep network that can fit into the available GPUs at the lab. The model was trained over 120 epochs using Stochastic Gradient Descent (SGD) on minibatches of 128 samples, with a learning rate of 0.01 and a Nesterov momentum of 0.9. The network has successfully learned the training data (final loss of 0.02) and has only very slightly overfitted. F1 scores for each AU on the test set are well over 0.9.

The video below shows the performance of the network in real conditions. The detected AUs are in the top-left corner, the recognized emotion in the bottom-left one.















  


<video controls >
  <source src="demo.mp4" type="video/mp4">
</video>


## Project 2 : Scene understanding

Recurrent neural networks coupled with attentional mechanisms have the ability to sequentially focus of the relevant parts of a visual scene. Coupled with a language production network, scene understanding abilities can be improved by finding the spatial location of the important objects in a scene while describing it.

The idea of the work done by Saransh Vora during his Master thesis in 2018 at the professorship was to study and reimplement the Show, attend and tell model of (Xu et al 2015, arXiv:1502.03044). The attentional signal is used to locate the most important objects of the sentence in the image, and have a Nao point at them while pronouncing the sentence.


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/dupgWkoA78c" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


-->

    </div>

    






<div class="article-tags">
  
  <a class="badge badge-light" href="/tag/machine-learning/">Machine Learning</a>
  
  <a class="badge badge-light" href="/tag/deep-learning/">deep-learning</a>
  
</div>



<div class="share-box" aria-hidden="true">
  <ul class="share">
    
      
      
      
        
      
      
      
      <li>
        <a href="https://twitter.com/intent/tweet?url=https://julien-vitay.net/project/deeplearning/&amp;text=Deep%20Learning" target="_blank" rel="noopener" class="share-btn-twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.facebook.com/sharer.php?u=https://julien-vitay.net/project/deeplearning/&amp;t=Deep%20Learning" target="_blank" rel="noopener" class="share-btn-facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="mailto:?subject=Deep%20Learning&amp;body=https://julien-vitay.net/project/deeplearning/" target="_blank" rel="noopener" class="share-btn-email">
          <i class="fas fa-envelope"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://www.linkedin.com/shareArticle?url=https://julien-vitay.net/project/deeplearning/&amp;title=Deep%20Learning" target="_blank" rel="noopener" class="share-btn-linkedin">
          <i class="fab fa-linkedin-in"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="whatsapp://send?text=Deep%20Learning%20https://julien-vitay.net/project/deeplearning/" target="_blank" rel="noopener" class="share-btn-whatsapp">
          <i class="fab fa-whatsapp"></i>
        </a>
      </li>
    
      
      
      
        
      
      
      
      <li>
        <a href="https://service.weibo.com/share/share.php?url=https://julien-vitay.net/project/deeplearning/&amp;title=Deep%20Learning" target="_blank" rel="noopener" class="share-btn-weibo">
          <i class="fab fa-weibo"></i>
        </a>
      </li>
    
  </ul>
</div>











  
  



  
  
  
    
  
  
  
  <div class="media author-card content-widget-hr">
    
      
      <a href="https://julien-vitay.net/"><img class="avatar mr-3 avatar-circle" src="/author/julien-vitay/avatar_hu5a54be5dd958dd9d4a68f29e82cd7573_195586_270x270_fill_q90_lanczos_center.jpg" alt="Julien Vitay"></a>
    

    <div class="media-body">
      <h5 class="card-title"><a href="https://julien-vitay.net/">Julien Vitay</a></h5>
      <h6 class="card-subtitle">Researcher in Computational Neuroscience and Artificial Intelligence</h6>
      <p class="card-text">Lab of AI, TU Chemnitz (Germany).</p>
      <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:julien.vitay@informatik.tu-chemnitz.de" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/JulienVitay" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.de/citations?user=1t5zJncAAAAJ" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/vitay" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
</ul>

    </div>
  </div>














  
  





    <div class="project-related-pages content-widget-hr">
      
      

      
      
      

      
      
      
        <h2>Publications</h2>
        
          
            








  
  





  


<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/publication/mummadi2021/" >Does enhanced shape bias improve neural network robustness to common corruptions?</a>
    </h3>

    
    <a href="/publication/mummadi2021/" class="summary-link">
      <div class="article-style">
        Convolutional neural networks (CNNs) learn to extract representations of complex features, such as object shapes and textures to solve …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  
  <span ><a href="/author/chaithanya-kumar-mummadi/">Chaithanya Kumar Mummadi</a></span>, <span ><a href="/author/ranjitha-subramaniam/">Ranjitha Subramaniam</a></span>, <span ><a href="/author/robin-hutmacher/">Robin Hutmacher</a></span>, <span ><a href="/author/julien-vitay/">Julien Vitay</a></span>, <span ><a href="/author/volker-fischer/">Volker Fischer</a></span>, <span ><a href="/author/jan-hendrik-metzen/">Jan Hendrik Metzen</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://arxiv.org/pdf/2104.09789.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/mummadi2021/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/deeplearning/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

          
        
          
            








  
  





  


<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/publication/schroeder2020/" >Monocular 3D Object Detection Using Feature Map Transformation: Towards Learning Perspective-Invariant Scene Representations</a>
    </h3>

    
    <a href="/publication/schroeder2020/" class="summary-link">
      <div class="article-style">
        In this paper we propose to use a feature map transformation network for the task of monocular 3D object detection. Given a monocular …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  
  <span ><a href="/author/enrico-schroder/">Enrico Schröder</a></span>, <span ><a href="/author/sascha-braun/">Sascha Braun</a></span>, <span ><a href="/author/mirko-mahlisch/">Mirko Mählisch</a></span>, <span ><a href="/author/julien-vitay/">Julien Vitay</a></span>, <span ><a href="/author/fred-h.-hamker/">Fred H. Hamker</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  





<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/schroeder2020/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/deeplearning/">
    Project
  </a>
  









<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://doi.org/10.1109/IRC.2020.00066" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

          
        
          
            








  
  





  


<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/publication/schroeder2019/" >Feature Map Transformation for Fusion of Multi-Sensor Object Detection Networks for Autonomous Driving</a>
    </h3>

    
    <a href="/publication/schroeder2019/" class="summary-link">
      <div class="article-style">
        We present a general framework for fusing pre-trained multisensor object detection networks for perception in autonomous cars at an …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  
  <span ><a href="/author/enrico-schroder/">Enrico Schröder</a></span>, <span ><a href="/author/sascha-braun/">Sascha Braun</a></span>, <span ><a href="/author/mirko-mahlisch/">Mirko Mählisch</a></span>, <span ><a href="/author/julien-vitay/">Julien Vitay</a></span>, <span ><a href="/author/fred-h.-hamker/">Fred H. Hamker</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/pdf/Schroeder2019.pdf" target="_blank" rel="noopener">
  PDF
</a>



<button type="button" class="btn btn-outline-primary my-1 mr-1 btn-sm js-cite-modal"
        data-filename="/publication/schroeder2019/cite.bib">
  Cite
</button>





  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/deeplearning/">
    Project
  </a>
  









<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://doi.org/10.1007/978-3-030-17798-0_12" target="_blank" rel="noopener">
  DOI
</a>



    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

          
        
          
            








  
  





  


<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/publication/forch2019/" >Recurrent Spatial Attention for Facial Emotion Recognition</a>
    </h3>

    
    <a href="/publication/forch2019/" class="summary-link">
      <div class="article-style">
        Automatic processing of emotion information through deep neural networks (DNN) can have great benefits for human-machine interaction. …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  
  <span ><a href="/author/valentin-forch/">Valentin Forch</a></span>, <span ><a href="/author/julien-vitay/">Julien Vitay</a></span>, <span ><a href="/author/fred-h.-hamker/">Fred H. Hamker</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/pdf/Forch2019.pdf" target="_blank" rel="noopener">
  PDF
</a>







  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/deeplearning/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

          
        
          
            








  
  





  


<div class="media stream-item">
  <div class="media-body">

    <h3 class="article-title mb-0 mt-0">
      <a href="/publication/schroeder2018/" >Fusion of Camera and Lidar Data for Object Detection using Neural Networks</a>
    </h3>

    
    <a href="/publication/schroeder2018/" class="summary-link">
      <div class="article-style">
        We present a novel architecture for intermediate fusion of Lidar and camera data for neural network-based object detection. Key …
      </div>
    </a>
    

    <div class="stream-meta article-metadata">

      

      
      <div>
        

  
  <span ><a href="/author/enrico-schroder/">Enrico Schröder</a></span>, <span ><a href="/author/mirko-mahlisch/">Mirko Mählisch</a></span>, <span ><a href="/author/julien-vitay/">Julien Vitay</a></span>, <span ><a href="/author/fred-h.-hamker/">Fred H. Hamker</a></span>
      </div>
      
    </div>

    
    <div class="btn-links">
      








  
    
  



<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://www.uni-das.de/images/pdf/veroeffentlichungen/2018/14_Fusion%20of%20Camera%20and%20Lidar%20Data%20for%20Object%20Detection%20using%20Neural%20Networks.pdf" target="_blank" rel="noopener">
  PDF
</a>







  
  <a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="/project/deeplearning/">
    Project
  </a>
  











    </div>
    

  </div>
  <div class="ml-3">
    
    
  </div>
</div>

          
        
      

      
      
      
    </div>
  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js" integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/highlight.min.js" integrity="sha512-TDKKr+IvoqZnPzc3l35hdjpHD0m+b2EC2SrLEgKDRWpxf2rFCxemkgvJ5kfU48ip+Y+m2XVKyOCD85ybtlZDmw==" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.2.0/languages/python.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.7.1/leaflet.min.js" integrity="sha512-SeiQaaDh73yrb56sTW/RgVdi/mMqNeM2oBwubFHagc5BkixSpP1fvqF47mKzPGWYSSy4RwbBunrJBQ4Co8fRWA==" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    
    
    
    
    <script>
      const search_config = {"indexURI":"/index.json","minLength":1,"threshold":0.3};
      const i18n = {"no_results":"No results found","placeholder":"Search...","results":"results found"};
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks",
        'slides' : "Slides"
        };
    </script>
    

    
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/wowchemy.min.434af0ebce9e15b273b954d65feb39c7.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    © Julien Vitay 2022
  </p>

  
  






  <p class="powered-by">
    
    Published with
    <a href="https://wowchemy.com" target="_blank" rel="noopener">Wowchemy</a>  —
    the free, <a href="https://github.com/wowchemy/wowchemy-hugo-modules" target="_blank" rel="noopener">
    open source</a> website builder that empowers creators.
    

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
