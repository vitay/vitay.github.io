
@inproceedings{Schroder2019,
  series = {Advances in {{Intelligent Systems}} and {{Computing}}},
  title = {Feature {{Map Transformation}} for {{Multi}}-Sensor {{Fusion}} in {{Object Detection Networks}} for {{Autonomous Driving}}},
  isbn = {978-3-030-17798-0},
  abstract = {We present a general framework for fusing pre-trained object detection networks for multiple sensor modalities in autonomous cars at an intermediate stage. The key innovation is an autoencoder-inspired Transformer module which transforms perspective as well as feature activation characteristics from one sensor modality to another. Transformed feature maps can be combined with those of a modality-native feature extractor to enhance performance and reliability through a simple fusion scheme. Our approach is not limited to specific object detection network types. Compared to other methods, our framework allows fusion of pre-trained object detection networks and fuses sensor modalities at a single stage, resulting in a modular and traceable architecture. We show effectiveness of the proposed scheme by fusing camera and Lidar information to detect objects using our own as well as the KITTI dataset.},
  language = {en},
  booktitle = {Advances in {{Computer Vision}}},
  publisher = {{Springer International Publishing}},
  author = {Schr{\"o}der, Enrico and Braun, Sascha and M{\"a}hlisch, Mirko and Vitay, Julien and Hamker, Fred},
  editor = {Arai, Kohei and Kapoor, Supriya},
  year = {2019},
  keywords = {Autonomous driving,Lidar,Object detection,Perception,Sensor fusion},
  pages = {118-131}
}
