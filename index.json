[{"authors":["admin"],"categories":null,"content":"I am researcher and lecturer at the TU Chemnitz, in the lab of Artificial Intelligence of the Faculty of Computer Science.\nI was previously postdoc in the Psychology Department of the University of Münster (Germany), under the supervision of Prof. Dr. Fred Hamker and a PhD student at Inria Nancy (France), in the Cortex lab headed by Dr. Frédéric Alexandre.\nMy research interests focus on computational neuroscience (basal ganglia, hippocampus, dopaminergic system) and neuro-informatics (neuro-simulator ANNarchy). I am also interested in machine learning, especially the recent advances in deep reinforcement learning.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://julien-vitay.net/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"I am researcher and lecturer at the TU Chemnitz, in the lab of Artificial Intelligence of the Faculty of Computer Science.\nI was previously postdoc in the Psychology Department of the University of Münster (Germany), under the supervision of Prof. Dr. Fred Hamker and a PhD student at Inria Nancy (France), in the Cortex lab headed by Dr. Frédéric Alexandre.\nMy research interests focus on computational neuroscience (basal ganglia, hippocampus, dopaminergic system) and neuro-informatics (neuro-simulator ANNarchy).","tags":null,"title":"Julien Vitay","type":"author"},{"authors":["Julien Vitay"],"categories":null,"content":"","date":1552734000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552734000,"objectID":"27267fa0a92187b285124d53514439c0","permalink":"https://julien-vitay.net/talk/clt2019/","publishdate":"2019-03-16T12:00:00+01:00","relpermalink":"/talk/clt2019/","section":"talk","summary":"Artificial Intelligence (AI) has become extremely popular in the last years through the advancement of Deep Learning, a modernized version of the good old neural networks. Deep Learning has enabled huge progress in pattern recognition, for example in object recognition or localization, speech recognition and synthesis, natural language understanding or in robotic control. These advances and the many novel applications that they allow seem to promise a bright future to AI, some self-proclaimed prophets even affirming that AI could soon be comparable to or even exceed human intelligence (the singularity). This presentation will look at the current state-of-the-art in deep learning and its applications, observe some of its limitations and discuss whether this is a suitable approach to Artificial General Intelligence.","tags":[],"title":"Deep Learning and Intelligence: the right approach?","type":"talk"},{"authors":["Enrico Schröder","Sascha Braun","Mirko Mählisch","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1548975600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548975600,"objectID":"224067ddf9af9618f72fffa8c2f6de1a","permalink":"https://julien-vitay.net/publication/schroeder2019/","publishdate":"2019-02-01T00:00:00+01:00","relpermalink":"/publication/schroeder2019/","section":"publication","summary":"We present a general framework for fusing pre-trained multisensor object detection networks for perception in autonomous cars at an intermediate stage using perspective invariant features. Key innovation is an autoencoder-inspired Transformer module which transforms perspective as well as feature activation layout from one sensor modality to another. Transformed feature maps can be combined with those of a modality-native object detector to enhance performance and reliability through a simple fusion scheme. Our approach is not limited to a specific object detection network architecture or even to specific sensor modalities. We show effectiveness of the proposed scheme through experiments on our own as well as on the KITTI dataset.","tags":[],"title":"Feature Map Transformation for Fusion of Multi-Sensor Object Detection Networks for Autonomous Driving","type":"publication"},{"authors":["Valentin Forch","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1548975600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548975600,"objectID":"de883880f2461fa1848db6b5c60dee4d","permalink":"https://julien-vitay.net/publication/forch2019/","publishdate":"2019-02-01T00:00:00+01:00","relpermalink":"/publication/forch2019/","section":"publication","summary":"Automatic processing of emotion information through deep neural networks (DNN) can have great benefits for human-machine interaction. Vice versa, machine learning can profit from concepts known from human information processing (e.g., visual attention). We employed a recurrent DNN incorporating a spatial attention mechanism for facial emotion recognition (FER) and compared the output of the network with results from human experiments. The attention mechanism enabled the network to select relevant face regions to achieve state-of-the-art performance on a FER database containing images from realistic settings. A visual search strategy showing some similarities with human saccading behavior emerged when the model’s perceptive capabilities were restricted. However, the model then failed to form a useful scene representation.","tags":[],"title":"Recurrent Spatial Attention for Facial Emotion Recognition","type":"publication"},{"authors":["Enrico Schröder","Mirko Mählisch","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1537912800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537912800,"objectID":"b4d1c4baafb0ba3a1770d7374ef3dc73","permalink":"https://julien-vitay.net/publication/schroeder2018/","publishdate":"2018-09-26T00:00:00+02:00","relpermalink":"/publication/schroeder2018/","section":"publication","summary":"We present a novel architecture for intermediate fusion of Lidar and camera data for neural network-based object detection. Key component is a transformer module which learns a transformation of feature maps from one sensor space to another. This allows large parts of the multi-modal object detection network to be trained unimodally, reducing the required amount of costly multi-modal labeled data. We show effectiveness of the transformer as well as the proposed fusion scheme.","tags":[],"title":"Fusion of Camera and Lidar Data for Object Detection using Neural Networks","type":"publication"},{"authors":["Francesc Villagrasa","Javier Baladron","Julien Vitay","Henning Schroll","Evan G. Antzoulatos","Earl K. Miller","Fred H. Hamker"],"categories":null,"content":"   ","date":1537221600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537221600,"objectID":"9accb64a61ade6f3b4f5a4a09806ea6b","permalink":"https://julien-vitay.net/publication/villagrasa2018/","publishdate":"2018-09-18T00:00:00+02:00","relpermalink":"/publication/villagrasa2018/","section":"publication","summary":"In addition to the prefrontal cortex (PFC), the basal ganglia (BG) have been increasingly often reported to play a fundamental role in category learning, but the systems-level circuits of how both interact remain to be explored. We developed a novel neuro-computational model of category learning that particularly addresses the BG-PFC interplay. We propose that the BG bias PFC activity by removing the inhibition of cortico-thalamo-cortical loop ahugo new --kind publication publication/nd thereby provide a teaching signal to guide the acquisition of category representations in the cortico-cortical associations to the PFC. Our model replicates key behavioral and physiological data of macaque monkey learning a prototype distortion task from Antzoulatos and Miller (2011). Our simulations allowed us to gain a deeper insight into the observed drop of category selectivity in striatal neurons seen in the experimental data and in the model. The simulation results and a new analysis of the experimental data, based on the model's predictions, show that the drop in category selectivity of the striatum emerges as the variability of responses in the striatum rises when confronting the BG with an increasingly larger number of stimuli to be classified. The neuro-computational model therefore provides new testable insights of systems-level brain circuits involved in category learning which may also be generalized to better understand other cortico-basal ganglia-cortical loops.","tags":["Basal Ganglia"],"title":"On the role of cortex-basal ganglia interactions for category learning: A neuro-computational approach","type":"publication"},{"authors":["Nicolas P. Rougier​","Konrad Hinsen","Frédéric Alexandre","Thomas Arildsen","Lorena A. Barba","Fabien C.Y. Benureau","C. Titus Brown","Pierre de Buyl","Ozan Caglayan","Andrew P. Davison","Marc-André Delsuc","Georgios Detorakis","Alexandra K. Diem","Damien Drix","Pierre Enel","Benoît Girard","Olivia Guest","Matt G. Hall","Rafael N. Henriques","Xavier Hinau","Kamil S. Jaron","Mehdi Khamassi","Almar Klein","Tiina Manninen","Pietro Marchesi","Daniel McGlinn","Christoph Metzner","Owen Petchey","Hans Ekkehard Plesser","Timothée Poisot","Karthik Ram","Yoav Ram","Etienne Roesch","Cyrille Rossant","Vahid Rostami","Aaron Shifman","Joseph Stachelek","Marcel Stimberg","Frank Stollmeier","Federico Vaggi","Guillaume Viejo","Julien Vitay","Anya E. Vostinar","Roman Yurchak","Tiziano Zito"],"categories":null,"content":"","date":1513551600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513551600,"objectID":"f20c0ac0dd0afc4a4702dba3c39076ad","permalink":"https://julien-vitay.net/publication/rougier2017/","publishdate":"2017-12-18T00:00:00+01:00","relpermalink":"/publication/rougier2017/","section":"publication","summary":"Computer science offers a large set of tools for prototyping, writing, running, testing, validating, sharing and reproducing results; however, computational science lags behind. In the best case, authors may provide their source code as a compressed archive and they may feel confident their research is reproducible. But this is not exactly true. James Buckheit and David Donoho proposed more than two decades ago that an article about computational results is advertising, not scholarship. The actual scholarship is the full software environment, code, and data that produced the result. This implies new workflows, in particular in peer-reviews. Existing journals have been slow to adapt: source codes are rarely requested and are hardly ever actually executed to check that they produce the results advertised in the article. ReScience is a peer-reviewed journal that targets computational research and encourages the explicit replication of already published research, promoting new and open-source implementations in order to ensure that the original research can be replicated from its description. To achieve this goal, the whole publishing chain is radically different from other traditional scientific journals. ReScience resides on GitHub where each new implementation of a computational study is made available together with comments, explanations, and software tests.","tags":[],"title":"Sustainable computational science: the ReScience initiative","type":"publication"},{"authors":["Lorenz Gönner","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"   ","date":1507759200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1507759200,"objectID":"5ee18f223459f73afd2e695e0d836572","permalink":"https://julien-vitay.net/publication/goenner2017/","publishdate":"2017-10-12T00:00:00+02:00","relpermalink":"/publication/goenner2017/","section":"publication","summary":"Hippocampal place-cell sequences observed during awake immobility often represent previous experience, suggesting a role in memory processes. However, recent reports of goals being overrepresented in sequential activity suggest a role in short-term planning, although a detailed understanding of the origins of hippocampal sequential activity and of its functional role is still lacking. In particular, it is unknown which mechanism could support efficient planning by generating place-cell sequences biased toward known goal locations, in an adaptive and constructive fashion. To address these questions, we propose a model of spatial learning and sequence generation as interdependent processes, integrating cortical contextual coding, synaptic plasticity and neuromodulatory mechanisms into a map-based approach. Following goal learning, sequential activity emerges from continuous attractor network dynamics biased by goal memory inputs. We apply Bayesian decoding on the resulting spike trains, allowing a direct comparison with experimental data. Simulations show that this model (1) explains the generation of never-experienced sequence trajectories in familiar environments, without requiring virtual self-motion signals, (2) accounts for the bias in place-cell sequences toward goal locations, (3) highlights their utility in flexible route planning, and (4) provides specific testable predictions.","tags":["Hippocampus"],"title":"Predictive Place-Cell Sequences for Goal-Finding Emerge from Goal Memory and the Cognitive Map: A Computational Model","type":"publication"},{"authors":["Winfried Lötzsch","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1505426400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1505426400,"objectID":"a24f863d8d69047e403f7186e9c773a2","permalink":"https://julien-vitay.net/publication/loetzsch2017/","publishdate":"2017-09-15T00:00:00+02:00","relpermalink":"/publication/loetzsch2017/","section":"publication","summary":"Recent advances in deep reinforcement learning methods have attracted a lot of attention, because of their ability to use raw signals such as video streams as inputs, instead of pre-processed state variables. However, the most popular methods (value-based methods, e.g. deep Q-networks) focus on discrete action spaces (e.g. the left/right buttons), while realistic robotic applications usually require a continuous action space (for example the joint space). Policy gradient methods, such as stochastic policy gradient or deep deterministic policy gradient, propose to overcome this problem by allowing continuous action spaces. Despite their promises, they suffer from long training times as they need huge numbers of interactions to converge. In this paper, we investigate in how far a recent asynchronously parallel actor-critic approach, initially proposed to speed up discrete RL algorithms, could be used for the continuous control of robotic arms. We demonstrate the capabilities of this end-to-end learning algorithm on a simulated 2 degrees-of-freedom robotic arm and discuss its applications to more realistic scenarios.","tags":[],"title":"Training a deep policy gradient-based neural network with asynchronous learners on a simulated robotic problem","type":"publication"},{"authors":["Julien Vitay"],"categories":null,"content":"","date":1483225200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483225200,"objectID":"cc66a1731bedfb6d463a98e9cd978104","permalink":"https://julien-vitay.net/publication/habilitation/","publishdate":"2017-01-01T00:00:00+01:00","relpermalink":"/publication/habilitation/","section":"publication","summary":"Neuro-computational models allow to study the brain mechanisms involved in intelligent behavior and extract essential computational principles which can be implemented in cognitive systems. They are a promising solution to achieve a brain-like artificial intelligence that can compete with natural intelligence on realistic behaviors. A crucial property of intelligent behavior is motivation, defined as the incentive to interact with the world in order to achieve specific goals, either extrinsic (obtaining rewards such as food or money, or avoiding pain) or intrinsic (satisfying one's curiosity, fun). In the human brain, motivated or goal-directed behavior depends on a network of different structures, including the prefrontal cortex, the basal ganglia and the limbic system. Dopamine, a neuro-transmitter associated with reward processing, plays a central role in coordinating the activity of this network. It structures processing in high-level cognitive areas along a limbic-associative-motor gradient and impacts the learning capabilities of the whole system. In this habilitation thesis, I present biologically-constrained neuro-computational models which investigate the role of dopamine in visual object categorization and memory retrieval (Vitay and Hamker, 2008), reinforcement learning and action selection (Vitay and Hamker, 2010), the updating, learning and maintenance of working memory (Schroll, Vitay and Hamker, 2012) and timing processes (Vitay and Hamker, 2014). These models outline the many mechanisms by which the dopaminergic system regulates cognitive and emotional behavior: bistable processing modes in the cerebral cortex, modulation of synaptic transmission and plasticity, allocation of cognitive resources and signaling of relevant events. Finally, I present a neural simulator able to simulate a variety of neuro-computational models efficiently on parallel architectures (Vitay, Dinkelbach and Hamker, 2015).","tags":[],"title":"On the role of dopamine in motivated behavior: a neuro-computational approach","type":"publication"},{"authors":["Julien Vitay"],"categories":null,"content":"","date":1475791200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475791200,"objectID":"900d705c07d22f88f8ca917bf52c2727","permalink":"https://julien-vitay.net/publication/vitay2016/","publishdate":"2016-10-07T00:00:00+02:00","relpermalink":"/publication/vitay2016/","section":"publication","summary":"A reference implementation of: Laje, R. and Buonomano, D.V. (2013). Robust timing and motor patterns by taming chaos in recurrent neural networks. Nat Neurosci. 16(7) pp 925-33 doi://10.1038/nn.3405","tags":[],"title":"[Re] Robust timing and motor patterns by taming chaos in recurrent neural networks","type":"publication"},{"authors":["Julien Vitay","Helge Ü. Dinkelbach","Fred H. Hamker"],"categories":null,"content":"","date":1438293600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1438293600,"objectID":"fb2b8185a2b906288014da0f95612741","permalink":"https://julien-vitay.net/publication/vitay2015/","publishdate":"2015-07-31T00:00:00+02:00","relpermalink":"/publication/vitay2015/","section":"publication","summary":"Many modern neural simulators focus on the simulation of networks of spiking neurons on parallel hardware. Another important framework in computational neuroscience, rate-coded neural networks, is mostly difficult or impossible to implement using these simulators. We present here the ANNarchy (Artificial Neural Networks architect) neural simulator, which allows to easily define and simulate rate-coded and spiking networks, as well as combinations of both. The interface in Python has been designed to be close to the PyNN interface, while the definition of neuron and synapse models can be specified using an equation-oriented mathematical description similar to the Brian neural simulator. This information is used to generate C++ code that will efficiently perform the simulation on the chosen parallel hardware (multi-core system or graphical processing unit). Several numerical methods are available to transform ordinary differential equations into an efficient C++code. We compare the parallel performance of the simulator to existing solutions.","tags":[],"title":"ANNarchy: a code generation approach to neural simulations on parallel hardware","type":"publication"},{"authors":["Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1391122800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1391122800,"objectID":"142022e3343b80d434ce33232072a5ff","permalink":"https://julien-vitay.net/publication/vitay2014/","publishdate":"2014-01-31T00:00:00+01:00","relpermalink":"/publication/vitay2014/","section":"publication","summary":"Neural activity in dopaminergic areas such as the ventral tegmental area is influenced by timing processes, in particular by the temporal expectation of rewards during Pavlovian conditioning. Receipt of a reward at the expected time allows to compute reward-prediction errors which can drive learning in motor or cognitive structures. Reciprocally, dopamine plays an important role in the timing of external events. Several models of the dopaminergic system exist, but the substrate of temporal learning is rather unclear. In this article, we propose a neuro-computational model of the afferent network to the ventral tegmental area, including the lateral hypothalamus, the pedunculopontine nucleus, the amygdala, the ventromedial prefrontal cortex, the ventral basal ganglia (including the nucleus accumbens and the ventral pallidum), as well as the lateral habenula and the rostromedial tegmental nucleus. Based on a plausible connectivity and realistic learning rules, this neuro-computational model reproduces several experimental observations, such as the progressive cancelation of dopaminergic bursts at reward delivery, the appearance of bursts at the onset of reward-predicting cues or the influence of reward magnitude on activity in the amygdala and ventral tegmental area. While associative learning occurs primarily in the amygdala, learning of the temporal relationship between the cue and the associated reward is implemented as a dopamine-modulated coincidence detection mechanism in the nucleus accumbens.","tags":[],"title":"Timing and expectation of reward: a neuro-computational model of the afferents to the ventral tegmental area","type":"publication"},{"authors":["Henning Schroll","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1388530800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388530800,"objectID":"cd70c3abdf22e2db7494c982d6734140","permalink":"https://julien-vitay.net/publication/schroll2014/","publishdate":"2014-01-01T00:00:00+01:00","relpermalink":"/publication/schroll2014/","section":"publication","summary":"In Parkinson's disease, a loss of dopamine neurons causes severe motor impairments. These motor impairments have long been thought to result exclusively from immediate effects of dopamine loss on neuronal firing in basal ganglia, causing imbalances of basal ganglia pathways. However, motor impairments and pathway imbalances may also result from dysfunctional synaptic plasticity – a novel concept of how Parkinsonian symptoms evolve. Here we built a neuro-computational model that allows us to simulate the effects of dopamine loss on synaptic plasticity in basal ganglia. Our simulations confirm that dysfunctional synaptic plasticity can indeed explain the emergence of both motor impairments and pathway imbalances in Parkinson's disease, thus corroborating the novel concept. By predicting that dysfunctional plasticity results not only in reduced activation of desired responses, but also in their active inhibition, our simulations provide novel testable predictions. When simulating dopamine replacement therapy (which is a standard treatment in clinical practice), we observe a new balance of pathway outputs, rather than a simple restoration of non-Parkinsonian states. In addition, high doses of replacement are shown to result in overshooting motor activity, in line with empirical evidence. Finally, our simulations provide an explanation for the intensely debated paradox that focused basal ganglia lesions alleviate Parkinsonian symptoms, but do not impair performance in healthy animals. Overall, our simulations suggest that the effects of dopamine loss on synaptic plasticity play an essential role in the development of Parkinsonian symptoms, thus arguing for a re-conceptualisation of Parkinsonian pathophysiology.","tags":[],"title":"Dysfunctional and compensatory synaptic plasticity in Parkinson's disease","type":"publication"},{"authors":["Helge Ü. Dinkelbach","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1352415600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1352415600,"objectID":"27c7e28c03cf8a736a2e525e01771fea","permalink":"https://julien-vitay.net/publication/dinkelbach2012/","publishdate":"2012-11-09T00:00:00+01:00","relpermalink":"/publication/dinkelbach2012/","section":"publication","summary":"Modern parallel hardware such as multi-core processors (CPUs) and graphics processing units (GPUs) have a high computational power which can be greatly beneficial to the simulation of large-scale neural networks. Over the past years, a number of efforts have focused on developing parallel algorithms and simulators best suited for the simulation of spiking neural models. In this article, we aim at investigating the advantages and drawbacks of the CPU and GPU parallelization of mean-firing rate neurons, widely used in systems-level computational neuroscience. By comparing OpenMP, CUDA and OpenCL implementations towards a serial CPU implementation, we show that GPUs are better suited than CPUs for the simulation of very large networks, but that smaller networks would benefit more from an OpenMP implementation. As this performance strongly depends on data organization, we analyze the impact of various factors such as data structure, memory alignment and floating precision. We then discuss the suitability of the different hardware depending on the networks' size and connectivity, as random or sparse connectivities in mean-firing rate networks tend to break parallel performance on GPUs due to the violation of coalescence.","tags":[],"title":"Comparison of GPU- and CPU-implementations of mean-firing rate neural networks on parallel hardware","type":"publication"},{"authors":["Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"3d3c75c126f95913dc31d83426b62a7c","permalink":"https://julien-vitay.net/publication/vitay2012/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/vitay2012/","section":"publication","summary":"","tags":[],"title":"Basal Ganglia learning","type":"publication"},{"authors":["Henning Schroll","Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1325372400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325372400,"objectID":"0bcdf51f9e0935e0ecd1d3a84ba7154e","permalink":"https://julien-vitay.net/publication/schroll2012/","publishdate":"2012-01-01T00:00:00+01:00","relpermalink":"/publication/schroll2012/","section":"publication","summary":"Cortico-basalganglio-thalamic loops are involved in both cognitive processes and motor control. We present a biologically meaningful computational model of how these loops contribute to the organization of working memory and the development of response behavior. Via reinforcement learning in basal ganglia, the model develops flexible control of working memory within prefrontal loops and achieves selection of appropriate responses based on working memory content and visual stimulation within a motor loop. We show that both working memory control and response selection can evolve within parallel and interacting cortico-basalganglio-thalamic loops by Hebbian and three-factor learning rules. Furthermore, the model gives a coherent explanation for how complex strategies of working memory control and response selection can derive from basic cognitive operations that can be learned via trial and error.","tags":[],"title":"Working memory and response selection: A computational account of interactions among cortico-basalganglio-thalamic loops","type":"publication"},{"authors":["Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1312149600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1312149600,"objectID":"bca3652d6e654b72c0afeb452d74d60b","permalink":"https://julien-vitay.net/publication/vitay2011/","publishdate":"2011-08-01T00:00:00+02:00","relpermalink":"/publication/vitay2011/","section":"publication","summary":"While classical theories systematically opposed emotion and cognition, suggesting that emotions perturbed the normal functioning of the rational thought, recent progress in neuroscience highlights on the contrary that emotional processes are at the core of cognitive processes, directing attention to emotionally-relevant stimuli, favoring the memorization of external events, valuating the association between an action and its consequences, biasing decision making by allowing to compare the motivational value of different goals and, more generally, guiding behavior towards fulfilling the needs of the organism. This article first proposes an overview of the brain areas involved in the emotional modulation of behavior and suggests a functional architecture allowing to perform efficient decision making. It then reviews a series of biologically-inspired computational models of emotion dealing with behavioral tasks like classical conditioning and decision making, which highlight the computational mechanisms involved in emotional behavior. It underlines the importance of embodied cognition in artificial intelligence, as emotional processing is at the core of the cognitive computations deciding which behavior is more appropriate for the agent. ","tags":[],"title":"A Neuroscientific View on the Role of Emotions in Behaving Cognitive Agents","type":"publication"},{"authors":["Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1274997600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1274997600,"objectID":"b30cd8b0a6ed1a89522b836117452908","permalink":"https://julien-vitay.net/publication/vitay2010/","publishdate":"2010-05-28T00:00:00+02:00","relpermalink":"/publication/vitay2010/","section":"publication","summary":"Visual working memory (WM) tasks involve a network of cortical areas such as inferotemporal, medial temporal and prefrontal cortices. We suggest here to investigate the role of the basal ganglia (BG) in the learning of delayed rewarded tasks through the selective gating of thalamocortical loops. We designed a computational model of the visual loop linking the perirhinal cortex, the BG and the thalamus, biased by sustained representations in prefrontal cortex. This model learns concurrently different delayed rewarded tasks that require to maintain a visual cue and to associate it to itself or to another visual object to obtain reward. The retrieval of visual information is achieved through thalamic stimulation of the perirhinal cortex. The input structure of the BG, the striatum, learns to represent visual information based on its association to reward, while the output structure, the substantia nigra pars reticulata, learns to link striatal representations to the disinhibition of the correct thalamocortical loop. In parallel, a dopaminergic cell learns to associate striatal representations to reward and modulates learning of connections within the BG. The model provides testable predictions about the behavior of several areas during such tasks, while providing a new functional organization of learning within the BG, putting emphasis on the learning of the striatonigral connections as well as the lateral connections within the substantia nigra pars reticulata. It suggests that the learning of visual WM tasks is achieved rapidly in the BG and used as a teacher for feedback connections from prefrontal cortex to posterior cortices.","tags":[],"title":"A computational model of basal ganglia and its role in memory retrieval in rewarded visual memory tasks","type":"publication"},{"authors":["Julien Vitay","Jérémy Fix","Frederik Beuth","Henning Schroll","Fred H. Hamker"],"categories":null,"content":"","date":1251756000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1251756000,"objectID":"4cc9f5e0799ad57e70b9e0248b482623","permalink":"https://julien-vitay.net/publication/vitay2009/","publishdate":"2009-09-01T00:00:00+02:00","relpermalink":"/publication/vitay2009/","section":"publication","summary":"This review focuses on biological issues of reinforcement learning. Since the influential discovery of W. Schultz of an analogy between the reward prediction error signal of the temporal difference algorithm and the firing pattern of some dopaminergic neurons in the midbrain during classical conditioning, biological models have emerged that use computational reinforcement learning concepts to explain adaptative behavior. In particular, the basal ganglia has been proposed to implement among other things reinforcement learning for action selection, motor control or working memory. We discuss to which extent the analogy between the temporal difference algorithm and the firing of dopamine cells can be considered as valid. Our review then focuses on the basal ganglia, their anatomy and key computational properties as demonstrated by three recent, influential models.","tags":[],"title":"Biological Models of Reinforcement Learning","type":"publication"},{"authors":["Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1223935200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1223935200,"objectID":"699cb152fef8e8d9e129f1d874a763b5","permalink":"https://julien-vitay.net/publication/vitay2008/","publishdate":"2008-10-14T00:00:00+02:00","relpermalink":"/publication/vitay2008/","section":"publication","summary":"The perirhinal cortex is involved not only in object recognition and novelty detection but also in multimodal integration, reward association, and visual working memory. We propose a computational model that focuses on the role of the perirhinal cortex in working memory, particularly with respect to sustained activities and memory retrieval. This model describes how different partial informations are integrated into assemblies of neurons that represent the identity of an object. Through dopaminergic modulation, the resulting clusters can retrieve the global information with recurrent interactions between neurons. Dopamine leads to sustained activities after stimulus disappearance that form the basis of the involvement of the perirhinal cortex in visual working memory processes. The information carried by a cluster can also be retrieved by a partial thalamic or prefrontal stimulation. Thus, we suggest that areas involved in planning and memory coordination encode a pointer to access the detailed information encoded in the associative cortex such as the perirhinal cortex.","tags":[],"title":"Sustained Activities and Retrieval in a Computational Model of the Perirhinal Cortex","type":"publication"},{"authors":["Julien Vitay","Fred H. Hamker"],"categories":null,"content":"","date":1167606000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1167606000,"objectID":"bac476c8ffcd2039eddd09b825f1ad1f","permalink":"https://julien-vitay.net/publication/vitay2007/","publishdate":"2007-01-01T00:00:00+01:00","relpermalink":"/publication/vitay2007/","section":"publication","summary":"Although dopamine is one of the most studied neurotransmitter in the brain, its exact function is still unclear. This short review focuses on its role in different levels of cognitive vision: visual processing, visual attention and working memory. Dopamine can influence cognitive vision either through direct modulation of visual cells or through gating of basal ganglia functioning. Even if its classically assigned role is to signal reward prediction error, we review evidence that dopamine is also involved in novelty detection and attention shifting and discuss the possible implications for computational modeling.","tags":[],"title":"On the role of dopamine in cognitive vision","type":"publication"},{"authors":["Julien Vitay"],"categories":null,"content":"","date":1151013600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1151013600,"objectID":"2945480723c2b451a5e837ea3d41dfbc","permalink":"https://julien-vitay.net/publication/phd/","publishdate":"2006-06-23T00:00:00+02:00","relpermalink":"/publication/phd/","section":"publication","summary":"This thesis ascribes in the field of computational neuroscience whose goal is to modelize complex cognitive functions by means of numerical computer simulations while getting inpiration from cerebral functioning. Contrary to a top-down approach necessiting to know an analytic expression of the function to be simulized, the chosen bottom-up approach allows to observe the emergence of a function thanks to the interaction of artificial neural populations without any prior knowledge. We first present a particular neural network type, neural fields, whose properties of robustness to noise and spatio-temporal continuity allow that emergence. In order to guide the emergence of sensorimotor transformations onto this substrate, we then present the architecture of the visual and motor systems to highlight the central role of visual attention in the realization of these functions by the brain. We then propose a functional diagram of sensorimotor transformations where the preparation of an ocular saccade guides attention towards a region of visual space and allow movement preparation. We last describe a computational model of attentional spotlight displacement that, by using a dynamical spatial working memory, allows sequential search of a target in a visual scene thanks to the phenomenom of inhibition of return. The performances of this model (robustness to noise, to object movement and to saccade execution) are analysed in simulation and on a robotic platform.","tags":[],"title":"Emergence of sensorimotor functions on a numerical distributed neural substrate","type":"publication"},{"authors":["Jérémy Fix","Julien Vitay","Nicolas P. Rougier"],"categories":null,"content":"","date":1136070000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1136070000,"objectID":"752a936880192382486303164b39aefa","permalink":"https://julien-vitay.net/publication/fix2006/","publishdate":"2006-01-01T00:00:00+01:00","relpermalink":"/publication/fix2006/","section":"publication","summary":"Some visual search tasks require to memorize the location of stimuli that have been previously scanned. Considerations about the eye movements raise the question of how we are able to maintain a coherent memory, despite the frequent drastically changes in the perception. In this article, we present a computational model that is able to anticipate the consequences of the eye movements on the visual perception in order to update a spatial memory.","tags":[],"title":"A computational model of spatial memory anticipation during visual search","type":"publication"},{"authors":["Nicolas P. Rougier","Julien Vitay"],"categories":null,"content":"","date":1117576800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1117576800,"objectID":"dc7fa3ac56ba9ce9ccfdf73981599746","permalink":"https://julien-vitay.net/publication/rougier2005/","publishdate":"2005-06-01T00:00:00+02:00","relpermalink":"/publication/rougier2005/","section":"publication","summary":"We present a dynamic model of attention based on the Continuum Neural Field Theory that explains attention as being an emergent property of a neural population. This model is experimentally proved to be very robust and able to track one static or moving target in the presence of very strong noise or in the presence of a lot of distractors, even more salient than the target. This attentional property is not restricted to the visual case and can be considered as a generic attentional process of any spatio-temporal continuous input.","tags":[],"title":"Emergence of attention within a neural population","type":"publication"},{"authors":["Julien Vitay","Nicolas P. Rougier","Frédéric Alexandre"],"categories":null,"content":"","date":1104534000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1104534000,"objectID":"4be0f60d95b2407ef701d218b7fe333a","permalink":"https://julien-vitay.net/publication/vitay2005/","publishdate":"2005-01-01T00:00:00+01:00","relpermalink":"/publication/vitay2005/","section":"publication","summary":"Although biomimetic autonomous robotics relies on the massively parallel architecture of the brain, the key issue is to temporally organize behaviour. The distributed representation of the sensory information has to be coherently processed to generate relevant actions. In the visual domain, we propose here a model of visual exploration of a scene by the means of localized computations in neural populations whose architecture allows the emergence of a coherent behaviour of sequential scanning of salient stimuli. It has been implemented on a real robotic platform exploring a moving and noisy scene including several identical targets.","tags":[],"title":"A distributed model of spatial visual attention","type":"publication"},{"authors":null,"categories":null,"content":" Neuro-computational models are different from classical neural networks (deep learning) in many aspects:\n The complexity of the neurons, whose activity is governed by one or several differential equations instead of a simple weighted sum. The complexity and diversity of the learning rules (synaptic plasticity), compared to gradient descent. The size of the networks needed to simulate significant parts of the brain. The huge diversity of models, architectures, frameworks used by researchers in computational neuroscience.  The increasing size of such networks asks for efficient parallel simulations, using distributed systems (OpenMP, MPI) or GPUs (CUDA). However, computational neuroscientists cannot be expected to be also experts in parallel computing. There is a need for a general-purpose neuro-simulator, with an easy but flexible interface allowing to define a huge variety of models, but which is internally efficient and allows for fast parallel simulations on various hardwares.\nOver many years, we have developed ANNarchy (Artificial Neural Networks architect), a parallel simulator for distributed rate-coded or spiking neural networks. The definition of the models is made in Python, but the library generates optimized C++ code to actually run the simulation on parallel hardware, using either openMP or CUDA. The current stable version is 4.6 and is released under the GNU GPL v2 or later.\nThe code is available at:\nhttps://bitbucket.org/annarchy/annarchy\nThe documentation is available at:\nhttps://annarchy.readthedocs.org\nCore principles ANNarchy separates the description of a neural network from its simulation. The description is declared in a Python script, offering high flexibility and readability of the code, and allowing to use the huge ecosystem of scientific libraries available with Python (Numpy, Scipy, Matplotlib\u0026hellip;). Using Python furthermore reduces the programming effort to a minimum, letting the modeller concentrate on network design and data analysis.\nA neural network is defined as a collection of interconnected populations of neurons. Each population comprises a set of similar artificial neurons (rate-coded or spiking point-neurons), whose activity is ruled by one or many ordinary differential equations. The activity of a neuron depends on the activity of other neurons through synapses, whose strength can evolve with time depending on pre- or post-synaptic activities (synaptic plasticity). Populations are interconnected with each other through projections, which contain synapses between two populations.\nANNarchy provides a set of classical neuron or synapse models, but also allows the definition of specific models. The ordinary differential equations (ODE) governing neural or synaptic dynamics have to be specified by the modeler. Contrary to other simulators (except Brian) which require to code these modules in a low-level language, ANNarchy provides a mathematical equation parser which can generate optimized C++ code depending on the chosen parallel framework. Bindings from C++ to Python are generated thanks to Cython (C-extensions to Python), which is a static compiler for Python. These bindings allow the Python script to access all data generated by the simulation (neuronal activity, connection weights) as if they were simple Python attributes. However, the simulation itself is independent from Python and its relatively low performance.\nExample of a pulse-coupled network of Izhikevich neurons To demonstrate the simplicity of ANNarchy\u0026rsquo;s interface, let\u0026rsquo;s focus on the \u0026ldquo;Hello, World!\u0026rdquo; of spiking networks: the pulse-coupled network of Izhikevich neurons (Izhikevich, 2003). It can be defined in ANNarchy as:\nfrom ANNarchy import * # Create the excitatory and inhibitory population pop = Population(geometry=1000, neuron=Izhikevich) Exc = pop[:800] ; Inh = pop[800:] # Set the population parameters re = np.random.random(800) ; ri = np.random.random(200) Exc.noise = 5.0 ; Inh.noise = 2.0 Exc.a = 0.02 ; Inh.a = 0.02 + 0.08 * ri Exc.b = 0.2 ; Inh.b = 0.25 - 0.05 * ri Exc.c = -65.0 + 15.0 * re**2 ; Inh.c = -65.0 Exc.d = 8.0 - 6.0 * re**2 ; Inh.d = 2.0 Exc.v = -65.0 ; Inh.v = -65.0 Exc.u = Exc.v * Exc.b ; Inh.u = Inh.v * Inh.b # Create the projections exc_proj = Projection(pre=Exc, post=pop, target='exc') exc_proj.connect_all_to_all(weights=Uniform(0.0, 0.5)) inh_proj = Projection(pre=Inh, post=pop, target='inh') inh_proj.connect_all_to_all(weights=Uniform(0.0, 1.0)) # Compile compile() # Start recording the spikes in the network to produce the plots M = Monitor(pop, ['spike', 'v']) # Simulate 1 second simulate(1000.0, measure_time=True) # Retrieve the spike recordings and the membrane potential spikes = M.get('spike') v = M.get('v') # Compute the raster plot t, n = M.raster_plot(spikes) # Compute the population firing rate fr = M.histogram(spikes) # Plot the results import matplotlib.pyplot as plt ax = plt.subplot(3,1,1) ax.plot(t, n, 'b.', markersize=1.0) ax = plt.subplot(3,1,2) ax.plot(v[:, 15]) ax = plt.subplot(3,1,3) ax.plot(fr) plt.show()  Publications Julien Vitay, Helge Ü. Dinkelbach, Fred H. Hamker (2015). ANNarchy: a code generation approach to neural simulations on parallel hardware. Front. Neuroinform. 9:19. doi: 10.3389/fninf.2015.00019.\nHelge Ü. Dinkelbach, Julien Vitay, Fred H. Hamker (2012). Comparison of GPU- and CPU-implementations of mean-firing rate neural networks on parallel hardware. Network: Computation in Neural Systems 23(4). doi:10.3109/0954898X.2012.739292.\n","date":2019,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":2019,"objectID":"bc653bba084e5cb400a33372aa0df56a","permalink":"https://julien-vitay.net/project/annarchy/","publishdate":"1970-01-01T01:33:39+01:00","relpermalink":"/project/annarchy/","section":"project","summary":"ANNarchy (Artificial Neural Networks architect) is a general-purpose parallel neuro-simulator for rate-coded or spiking neural networks.","tags":["parallel computing","computational neuroscience"],"title":"ANNarchy","type":"project"},{"authors":null,"categories":null,"content":" The recent hype on deep learning has revived the interest for artificial neural networks and their applications. Here are some projects done lately.\nProject 1 : Facial emotion recognition Facial expression recognition is an important research field in computer vision. Although detecting facial features is an easy task for a human, computers still have a hard time doing it. Factors such as interpersonal variation (gender, skin color), intrapersonal variation (pose, expression) and different recording conditions (image resolution, lighting) add to the complexity of the problem. This is particularly relevant in the context of emotion recognition, where systems should be able to automatically recognize in which emotional state humans are.\nOn human faces, emotional expression heavily relies on the activation of individual facial muscles. A classical approach to describe facial expressions at the muscular level is the Facial Action Coding System (FACS) proposed by Ekman (1978). In this framework, movement of specific facial regions are described as Actions Units (AU), which basically describe deviations from a neutral expression. AUs are specific to facial regions (corner of the mouth or the eye, etc.). Although there are 69 AUs in the FACS theory, 28 of them are mostly useful for emotion recognition. We have focused on 12 of them: 1 (Inner Brow Raiser), 2 (Outer Brow Raiser), 4 (Brow Lowerer), 6 (Cheek Raiser), 7 (Lid Tightener), 10 (Upper Lip Raiser), 12 (Lip Corner Puller), 14 (Dimpler), 15 (Lip Corner Depressor), 17 (Chin Raiser), 23 (Lip Tightener), 24 (Lip Pressor).\nThere are different training sets generally available to the community containing various number of FACS-annotated images, with different numbers of annotated AUs: CCK+, MMI, UNBC-McMaster PAIN, DUSFA, BP4D, SEMAINE, etc. The 12 selected AUs correspond to the annotated AUs in BP4D, which is the most massive dataset. The main interest of these AUs is that they are mostly sufficient to predict the occurence of the 6 basic emotions using the EMFACS correspondance table:\n   Emotion Action Units     Happiness 6, 12   Sadness 1, 4, 15   Surprise 1, 2, 5B, 26   Fear 1, 2, 4, 5, 7, 20, 26   Anger 4, 5, 7, 23   Disgust 9, 15, 16    After investigating various architectures to automatically predict AU occurence on faces, we converged towards a neural network architecture inspired from VGG-16:\n Convolutional Neural Network for FACS recognition.   It consists of 4 convolutional blocks, each composed of 2 convolutional layers (kernel size 3x3, ReLU activation function) and a max-pooling layers (2x2). A dropout layer with p=0.2 is added after the max-pooling. After 4 such convolutional blocks with increasing numbers of features (32, 64, 126 and 256), the last tensor (6x6x256) is flattened into a vector of 9216 elements and projected on a fully connected layer of 500 neurons. The output layer has 12 neurons using the sigmoid activation function, each representing one of the 12 AUs present in the combined dataset. The network has a total of 5.786.192 trainable parameters (weights and biases), what makes it a middle-sized deep network that can fit into the available GPUs at the lab. The model was trained over 120 epochs using Stochastic Gradient Descent (SGD) on minibatches of 128 samples, with a learning rate of 0.01 and a Nesterov momentum of 0.9. The network has successfully learned the training data (final loss of 0.02) and has only very slightly overfitted. F1 scores for each AU on the test set are well over 0.9.\nThe video below shows the performance of the network in real conditions. The detected AUs are in the top-left corner, the recognized emotion in the bottom-left one.\n Project 2 : Scene understanding Recurrent neural networks coupled with attentional mechanisms have the ability to sequentially focus of the relevant parts of a visual scene. Coupled with a language production network, scene understanding abilities can be improved by finding the spatial location of the important objects in a scene while describing it.\nThe idea of the work done by Saransh Vora during his Master thesis in 2018 at the professorship was to study and reimplement the Show, attend and tell model of (Xu et al 2015, arXiv:1502.03044). The attentional signal is used to locate the most important objects of the sentence in the image, and have a Nao point at them while pronouncing the sentence.\n  Publications Enrico Schröder, Mirko Mählisch, Julien Vitay, Fred H. Hamker (2018). Fusion of Camera and Lidar Data for Object Detection using Neural Networks. In Proceedings of 12. Workshop Fahrerassistenzsysteme und automatisiertes Fahren FAS 2018, 26-28.09.2018, Walting im Altmühltal (Germany). pp138-146. Darmstadt:Uni-DAS e.V..\nEnrico Schröder, Sascha Braun, Mirko Mählisch, Julien Vitay, Fred H. Hamker (2019). Feature Map Transformation for Fusion of Multi-Sensor Object Detection Networks for Autonomous Driving. In Computer Vision Conference (CVC), Las Vegas (Nevada).\nValentin Forch, Julien Vitay, Fred H. Hamker (2019). Recurrent Spatial Attention for Facial Emotion Recognition. In Proceedings of Workshop Localize IT, Chemnitz Linux-Tage, Chemnitz (Germany).\n","date":2019,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":2019,"objectID":"e852b07eddb0686d7d5ddcd7824f9387","permalink":"https://julien-vitay.net/project/deeplearning/","publishdate":"1970-01-01T01:33:39+01:00","relpermalink":"/project/deeplearning/","section":"project","summary":"Deep neural networks and their applications to emotion recognition, attention, sensor fusion...","tags":["machine-learning","deep-learning"],"title":"Deep Learning","type":"project"},{"authors":null,"categories":null,"content":" The dopaminergic system is composed of the ventral tegmental area (VTA) and the substantia nigra pars compacta (SNc). The neurotransmitter dopamine (DA) released by neurons in these two small areas exerts a strong influence on neural excitability and plasticity in many brain areas: mostly the basal ganglia (BG), but also the prefrontal cortex, the hippocampus or the amygdala.\nA striking feature of VTA cells is their response during classical (or Pavlovian) conditioning, as observed by Schultz et al (1998). Early on, VTA cells respond phasically (a burst) to unconditioned stimuli (US, or rewards in operant conditioning). Gradually during learning, the amplitude of this response decreases, replaced by a response to the conditioned stimuli (CS) which are predictive of reward delivery. Moreover, if a reward is predicted by the CS but omitted, VTA cells show a brief depression of activity (a dip) at the time where the US was expected. This pattern resembles the temporal difference (TD) error signal used in reinforcement learning, what generated multitudes of models based on that analogy.\nWhat remains unclear is how VTA cells access information about the US, the CS and more importantly the time elapsed since CS onset. The goal of this research project is to investigate the mechanisms by which VTA is able to exhibit these properties, by looking at the afferent system to VTA. VTa indeed receives information from many brain areas, either directly as the rostromedial tegmental area (RMTg), the pedunculopontine nucleus (PPTN) or the nucleus accumbens (NAcc), or indirectly as the amygdala, the lateral habenula (LHb), the ventral pallidum (VP) or the ventromedial prefrontal cortex (vmPFC).\nPublications Julien Vitay (2017). On the role of dopamine in motivated behavior: a neuro-computational approach. Habilitation (TU Chemnitz).\nJulien Vitay, Fred H. Hamker (2014). Timing and expectation of reward: a neuro-computational model of the afferents to the ventral tegmental area. Front. Neurorobot. 8:4. doi:10.3389/fnbot.2014.00004.\n","date":2019,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":2019,"objectID":"e26cb680b5b5bd2046cc8002093cf86c","permalink":"https://julien-vitay.net/project/dopamine/","publishdate":"1970-01-01T01:33:39+01:00","relpermalink":"/project/dopamine/","section":"project","summary":"Modeling the dopaminergic system (VTA, SNc), its afferences and its influence on the basal ganglia, prefrontal cortex and hippocampus.","tags":["computational-neuroscience"],"title":"Dopaminergic system","type":"project"},{"authors":["Julien Vitay"],"categories":null,"content":" ANNarchy (Artificial Neural Networks architect) Julien Vitay ANNarchy (Artificial Neural Networks architect)  Source code:  https://bitbucket.org/annarchy/annarchy\n Documentation:  https://annarchy.readthedocs.io/en/stable/\n Forum:  https://groups.google.com/forum/#!forum/annarchy\n Notebooks used in this tutorial:  https://github.com/vitay/ANNarchy-notebooks\nInstallation Installation guide: https://annarchy.readthedocs.io/en/stable/intro/Installation.html\n From pip:  pip install ANNarchy   From source:  git clone https://bitbucket.org/annarchy/annarchy.git cd annarchy python setup.py install   Requirements (Linux and MacOS):\n g++/clang++, python 2.7 or 3.5+, numpy, scipy, matplotlib, sympy, cython   Features  Simulation of both rate-coded and spiking neural networks.\n Only local biologically realistic mechanisms are possible (no backpropagation).\n Equation-oriented description of neural/synaptic dynamics (à la Brian).\n Code generation in C++, parallelized using OpenMP on CPU and CUDA on GPU (MPI is coming).\n Synaptic, intrinsic and structural plasticity mechanisms.\n  Structure of a script from ANNarchy import * setup(dt=1.0) neuron = Neuron(...) # Create neuron types stdp = Synapse(...) # Create synapse types for transmission and/or plasticity pop = Population(1000, neuron) # Create populations of neurons proj = Projection(pop, pop, 'exc', stdp) # Connect the populations proj.connect_fixed_probability(weights=0.0, probability=0.1) compile() # Generate and compile the code m = Monitor(pop, ['spike']) # Record spikes simulate(1000.) # Simulate for 1 second data = m.get('spike') # Retrieve the data and plot it  1 - Rate-coded networks Example 1 : Echo-State Network Echo-State Network ESN rate-coded neurons typically follow first-order ODEs:\n$$ \\tau \\frac{dx(t)}{dt} + x(t) = \\sum w^\\text{in} \\, r^\\text{in}(t) + g \\, \\sum w^\\text{rec} \\, r(t) + \\xi(t) $$\n$$ r(t) = \\tanh(x(t)) $$\nfrom ANNarchy import * ESN_Neuron = Neuron( parameters = \u0026quot;\u0026quot;\u0026quot; tau = 30.0 # Time constant g = 1.0 : population # Scaling noise = 0.01 : population # Noise amplitude \u0026quot;\u0026quot;\u0026quot;, equations=\u0026quot;\u0026quot;\u0026quot; tau * dx/dt + x = sum(in) + g * sum(exc) + noise * Uniform(-1, 1) : init=0.0 r = tanh(x) \u0026quot;\u0026quot;\u0026quot; )  Parameters parameters = \u0026quot;\u0026quot;\u0026quot; tau = 30.0 # Time constant g = 1.0 : population # Scaling noise = 0.01 : population # Noise amplitude \u0026quot;\u0026quot;\u0026quot;   All parameters used in the equations must be declared in the Neuron definition.\n Parameters can have one value per neuron in the population (default) or be common to all neurons (flag population or projection).\n Parameters and variables are double floats by default, but the type can be specified (int, bool).\n  Variables equations=\u0026quot;\u0026quot;\u0026quot; tau * dx/dt + x = sum(in) + g * sum(exc) + noise * Uniform(-1, 1) : init=0.0 r = tanh(x) \u0026quot;\u0026quot;\u0026quot;   Variables are evaluated at each time step in the order of their declaration, except for coupled ODEs.\n Variables can be updated with assignments (=, +=, etc) or by defining first order ODEs.\n The math C library symbols can be used (tanh, cos, exp, etc).\n Initial values at $t=0$ can be specified with init (default: 0.0).\n Lower/higher bounds on the values of the variables can be set with the min/max flags:\n  r = x : min=0.0 # ReLU   Additive noise can be drawn from several distributions, including Uniform, Normal, LogNormal, Exponential, Gamma\u0026hellip;\n The output variable of a rate-coded neuron must be r.\n  ODEs  First-order ODEs are parsed and manipulated using sympy:  # All equivalent: tau * dx/dt + x = 0.0 tau * dx/dt = - x dx/dt = (-x)/tau   Several numerical methods are available (https://annarchy.readthedocs.io/en/stable/manual/NumericalMethods.html):\n Explicit (forward) Euler (default): tau * dx/dt + x = 0.0 : init=0.0, explicit\n Implicit (backward) Euler: tau * dx/dt + x = 0.0 : init=0.0, implicit\n Exponential Euler (exact for linear ODE): tau * dx/dt + x = 0.0 : init=0.0, exponential\n Midpoint (RK2): tau * dx/dt + x = 0.0 : init=0.0, midpoint\n Event-driven (spiking synapses): tau * dx/dt + x = 0.0 : init=0.0, event-driven\n   Coupled ODEs  ODEs are solved concurrently, instead of sequentially for assignments:  # I is updated I = sum(exc) - sum(inh) + b # u and v are solved concurrently using the current of I tau * dv/dt + v = I - u tau * du/dt + u = v # r uses the updated value of v r = tanh(v)   The order of the equations therefore matters a lot.\n A single variable can only be updated once in the equations field.\n  Populations  Populations are creating by specifying a number of neurons and a neuron type:  pop = Population(1000, ESN_Neuron)   For visualization purposes or when using convolutional layers, a tuple geometry can be passed instead of the size:  pop = Population((100, 100), ESN_Neuron)   All parameters and variables become attributes of the population (read and write) as numpy arrays:  pop.tau = np.linspace(20.0, 40.0, 1000) pop.r = np.tanh(pop.v)   Single neurons can be individually modified, if the population flag was not set:  pop[10].r = 1.0   Slices of populations are called PopulationView and can be addressed separately:  pop = Population(1000, ESN_Neuron) E = pop[:800] I = pop[800:]  Projections  Projections link two populations (or views) in a uni-directional way.  proj_exc = Projection(E, pop, 'exc') proj_inh = Projection(I, pop, 'inh')   Each target ('exc', 'inh', 'AMPA', 'NMDA', 'GABA') can be defined as needed and will be treated differently by the post-synaptic neurons.\n The weighted sum of inputs for a specific target is accessed in the equations by sum(target):\n  equations=\u0026quot;\u0026quot;\u0026quot; tau * dx/dt + x = sum(exc) - sum(inh) r = tanh(x) \u0026quot;\u0026quot;\u0026quot;   It is therefore possible to model modulatory effects, divisive inhibition, etc.  Connection methods  Projections must be populated with a connectivity matrix (who is connected to who), a weight w and optionally a delay d (uniform or variable).\n Several patterns are predefined:\n  proj.connect_all_to_all(weights=Normal(0.0, 1.0), delays=2.0, allow_self_connections=False) proj.connect_one_to_one(weights=1.0, delays=Uniform(1.0, 10.0)) proj.connect_fixed_number_pre(number=20, weights=1.0) proj.connect_fixed_number_post(number=20, weights=1.0) proj.connect_fixed_probability(probability=0.2, weights=1.0) proj.connect_gaussian(amp=1.0, sigma=0.2, limit=0.001) proj.connect_dog(amp_pos=1.0, sigma_pos=0.2, amp_neg=0.3, sigma_neg=0.7, limit=0.001)   But you can also load Numpy arrays or Scipy sparse matrices. Example for synfire chains:  w = np.array([[None]*pre.size]*post.size) for i in range(post.size): w[i, (i-1)%pre.size] = 1.0 proj.connect_from_matrix(w) w = lil_matrix((pre.size, post.size)) for i in range(pre.size): w[pre.size, (i+1)%post.size] = 1.0 proj.connect_from_sparse(w)  Compiling and running the simulation  Once all populations and projections are created, you have to generate to the C++ code and compile it:  compile()   You can now manipulate all parameters/variables from Python thanks to the Cython bindings.\n A simulation is simply run for a fixed duration with:\n  simulate(1000.) # 1 second   You can also run a simulation until a criteria is filled, check:  https://annarchy.readthedocs.io/en/stable/manual/Simulation.html#early-stopping\nMonitoring  By default, a simulation is run in C++ without interaction with Python.\n You may want to record some variables (neural or synaptic) during the simulation with a Monitor:\n  m = Monitor(pop, ['v', 'r']) n = Monitor(proj, ['w'])   After the simulation, you can retrieve the recordings with:  recorded_v = m.get('v') recorded_r = m.get('r') recorded_w = n.get('w')   Warning: calling get() flushes the array.\n Warning: recording projections can quickly fill up the RAM (see Dendrites).\n  Example 1: Echo-State Network  Link to the Jupyter notebook on github: RC.ipynb  2 - Spiking networks Spiking neurons  Spiking neurons must also define two additional fields:\n spike: condition for emitting a spike.\n reset: what happens after a spike is emitted (at the start of the refractory period).\n  A refractory period in ms can also be specified.\n Example of the Leaky Integrate-and-Fire:\n  LIF = Neuron( parameters=\u0026quot;\u0026quot;\u0026quot; tau = 20. E_L = -70. v_T = 0. v_r = -58. I = 50.0 \u0026quot;\u0026quot;\u0026quot;, equations=\u0026quot;\u0026quot;\u0026quot; tau * dv/dt = (E_L - v) + I : init=E_L \u0026quot;\u0026quot;\u0026quot;, spike=\u0026quot; v \u0026gt;= v_T \u0026quot;, reset=\u0026quot; v = v_r \u0026quot;, refractory = 2.0 )  Conductances / currents  A pre-synaptic spike arriving to a spiking neuron increase the conductance g_target (e.g. g_exc or g_inh, depending on the projection).  LIF = Neuron( parameters=\u0026quot;...\u0026quot;, equations=\u0026quot;\u0026quot;\u0026quot; tau * dv/dt = (E_L - v) + g_exc - g_inh \u0026quot;\u0026quot;\u0026quot;, spike=\u0026quot; v \u0026gt;= v_T \u0026quot;, reset=\u0026quot; v = v_r \u0026quot;, refractory = 2.0 )   Each spike increments g_target from the synaptic efficiency w of the corresponding synapse.  g_target += w   This defines an instantaneous model of synaptic transmission.  Conductances / currents  For exponentially-decreasing or alpha-shaped synapses, ODEs have to be introduced for the conductance/current.\n The exponential numerical method should be preferred, as integration is exact.\n  LIF = Neuron( parameters=\u0026quot;...\u0026quot;, equations=\u0026quot;\u0026quot;\u0026quot; tau * dv/dt = (E_L - v) + g_exc + alpha_exc # exponential or alpha tau_exc * dg_exc/dt = - g_exc : exponential tau_exc * dalpha_exc/dt = exp((tau_exc - dt/2.0)/tau_exc) * g_exc - alpha_exc : exponential \u0026quot;\u0026quot;\u0026quot;, spike=\u0026quot; v \u0026gt;= v_T \u0026quot;, reset=\u0026quot; v = v_r \u0026quot;, refractory = 2.0 )  Conductances / currents Example 2: AdEx - Adaptive exponential neuron  Link to the Jupyter notebook on github: AdEx.ipynb  $$ \\tau \\, \\frac{dv}{dt} = (E_L - v) + \\delta_T \\, \\exp \\frac{v-v_T}{\\delta_T} + I - w $$ $$ \\tau_w \\, \\frac{dw}{dt} = a \\, (v - E_L) - w $$\nAdEx = Neuron( parameters=\u0026quot;\u0026quot;\u0026quot; tau = 20. E_L = -70. v_T = -50. ; v_r = -58. delta_T = 2.0 a = 0.2 ; b = 0. tau_w = 30. I = 50.0 \u0026quot;\u0026quot;\u0026quot;, equations=\u0026quot;\u0026quot;\u0026quot; tau * dv/dt = (E_L - v) + delta_T * exp((v-v_T)/delta_T) + I - w : init=E_L tau_w * dw/dt = a * (v - E_L) - w : init=0.0 \u0026quot;\u0026quot;\u0026quot;, spike=\u0026quot; v \u0026gt;= 0.0 \u0026quot;, reset=\u0026quot; v = v_r ; w += b \u0026quot;, refractory = 2.0 )  3 - Synaptic plasticity Rate-coded synapses : Intrator \u0026amp; Cooper BCM learning rule  Synapses can also implement equations that will be evaluated after each neural update.  IBCM = Synapse( parameters = \u0026quot;\u0026quot;\u0026quot; eta = 0.01 : projectionAdEx tau = 2000.0 : projection \u0026quot;\u0026quot;\u0026quot;, equations = \u0026quot;\u0026quot;\u0026quot; tau * dtheta/dt + theta = post.r^2 : postsynaptic, exponential dw/dt = eta * post.r * (post.r - theta) * pre.r : min=0.0, explicit \u0026quot;\u0026quot;\u0026quot;, psp = \u0026quot; w * pre.r\u0026quot; )   The synaptic efficiency (weight) must be w.\n Each synapse can access pre- and post-synaptic variables with pre. and post..\n The postsynaptic flag allows to do computations only once per post-synaptic neurons.\n psp optionally defines what will be summed by the post-synaptic neuron (e.g. psp = \u0026quot;w * log(pre.r)\u0026quot;).\n  Plastic projections  The synapse type just has to be passed to the Projection:  proj = Projection(inp, pop, 'exc', IBCM)   Synaptic variables can be accessed as lists of lists for the whole projection:  proj.w proj.theta  or for a single post-synaptic neuron (Dendrite):\nproj[10].w  Example 3: Miconi\u0026rsquo;s reward modulated RC network  Link to the Jupyter notebook on github: Miconi.ipynb  Spiking synapses : Example of Short-term plasticity (STP)  Spiking synapses can define a pre_spike field, defining what happens when a pre-synaptic spike arrives at the synapse.\n g_target is an alias for the corresponding post-synaptic conductance: it will be replaced by g_exc or g_inh depending on how the synapse is used.\n By default, a pre-synaptic spike increments the post-synaptic conductance from w: g_target += w\n  STP = Synapse( parameters = \u0026quot;\u0026quot;\u0026quot; tau_rec = 100.0 : projection tau_facil = 0.01 : projection U = 0.5 \u0026quot;\u0026quot;\u0026quot;, equations = \u0026quot;\u0026quot;\u0026quot; dx/dt = (1 - x)/tau_rec : init = 1.0, event-driven du/dt = (U - u)/tau_facil : init = 0.5, event-driven \u0026quot;\u0026quot;\u0026quot;, pre_spike=\u0026quot;\u0026quot;\u0026quot; g_target += w * u * x x *= (1 - u) u += U * (1 - u) \u0026quot;\u0026quot;\u0026quot; )  Spiking synapses : Example of Spike-Timing Dependent plasticity (STDP)  post_spike similarly defines what happens when a post-synaptic spike is emitted.  STDP = Synapse( parameters = \u0026quot;\u0026quot;\u0026quot; tau_plus = 20.0 : projection ; tau_minus = 20.0 : projection A_plus = 0.01 : projection ; A_minus = 0.01 : projection w_min = 0.0 : projection ; w_max = 1.0 : projection \u0026quot;\u0026quot;\u0026quot;, equations = \u0026quot;\u0026quot;\u0026quot; tau_plus * dx/dt = -x : event-driven # pre-synaptic trace tau_minus * dy/dt = -y : event-driven # post-synaptic trace \u0026quot;\u0026quot;\u0026quot;, pre_spike=\u0026quot;\u0026quot;\u0026quot; g_target += w x += A_plus * w_max w = clip(w + y, w_min , w_max) \u0026quot;\u0026quot;\u0026quot;, post_spike=\u0026quot;\u0026quot;\u0026quot; y -= A_minus * w_max w = clip(w + x, w_min , w_max) \u0026quot;\u0026quot;\u0026quot;)  Spiking synapses : Example of Spike-Timing Dependent plasticity (STDP) And much more\u0026hellip;  Standard populations (SpikeSourceArray, TimedArray, PoissonPopulation, HomogeneousCorrelatedSpikeTrains), OpenCV bindings.\n Standard neurons:\n LeakyIntegrator, Izhikevich, IF_curr_exp, IF_cond_exp, IF_curr_alpha, IF_cond_alpha, HH_cond_exp, EIF_cond_exp_isfa_ista, EIF_cond_alpha_isfa_ista  Standard synapses:\n Hebb, Oja, IBCM, STP, STDP  Parallel simulations with parallel_run.\n Convolutional and pooling layers.\n Hybrid rate-coded / spiking networks.\n Structural plasticity.\n  RTFD: https://annarchy.readthedocs.io\n","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"ae5f560c4e7277f9aad09de95c05ce85","permalink":"https://julien-vitay.net/slides/annarchy/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/slides/annarchy/","section":"slides","summary":"ANNarchy (Artificial Neural Networks architect) Julien Vitay ANNarchy (Artificial Neural Networks architect)  Source code:  https://bitbucket.org/annarchy/annarchy\n Documentation:  https://annarchy.readthedocs.io/en/stable/\n Forum:  https://groups.google.com/forum/#!forum/annarchy\n Notebooks used in this tutorial:  https://github.com/vitay/ANNarchy-notebooks\nInstallation Installation guide: https://annarchy.readthedocs.io/en/stable/intro/Installation.html\n From pip:  pip install ANNarchy   From source:  git clone https://bitbucket.org/annarchy/annarchy.git cd annarchy python setup.py install   Requirements (Linux and MacOS):\n g++/clang++, python 2.7 or 3.5+, numpy, scipy, matplotlib, sympy, cython   Features  Simulation of both rate-coded and spiking neural networks.","tags":null,"title":"Introduction to ANNarchy","type":"slides"}]