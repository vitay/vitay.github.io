{"title":"ANNarchy (Artificial Neural Networks architect)","markdown":{"yaml":{"title":"ANNarchy (Artificial Neural Networks architect)","toc":false},"headingText":"Core principles","containsRefs":false,"markdown":"\n\nNeuro-computational models are different from classical neural networks (deep learning) in many aspects:\n\n* The complexity of the neurons, whose activity is governed by one or several differential equations instead of a simple weighted sum.\n* The complexity and diversity of the learning rules (synaptic plasticity), compared to gradient descent.\n* The size of the networks needed to simulate significant parts of the brain.\n* The huge diversity of models, architectures, frameworks used by researchers in computational neuroscience.\n\nThe increasing size of such networks asks for efficient parallel simulations, using distributed systems (OpenMP, MPI) or GPUs (CUDA). However, computational neuroscientists cannot be expected to be also experts in parallel computing. There is a need for a general-purpose neuro-simulator, with an easy but flexible interface allowing to define a huge variety of models, but which is internally efficient and allows for fast parallel simulations on various hardwares.\n\nOver many years, we have developed **ANNarchy** (Artificial Neural Networks architect), a parallel simulator for distributed rate-coded or spiking neural networks. The definition of the models is made in Python, but the library generates optimized C++ code to actually run the simulation on parallel hardware, using either openMP or CUDA. The current stable version is 4.7 and is released under the GNU GPL v2 or later.\n\nThe code is available at:\n\n<https://github.com/ANNarchy/ANNarchy>\n\nThe documentation is available at:\n\n<https://annarchy.github.io>\n\n\nANNarchy separates the description of a neural network from its simulation. The description is declared in a Python script, offering high flexibility and readability of the code, and allowing to use the huge ecosystem of scientific libraries available with Python (Numpy, Scipy, Matplotlib...). Using Python furthermore reduces the programming effort to a minimum, letting the modeller concentrate on network design and data analysis.\n\n![](../img/annarchy.svg)\n\nA neural network is defined as a collection of interconnected populations of neurons. Each population comprises a set of similar artificial neurons (rate-coded or spiking point-neurons), whose activity is ruled by one or many ordinary differential equations. The activity of a neuron depends on the activity of other neurons through synapses, whose strength can evolve with time depending on pre- or post-synaptic activities (synaptic plasticity). Populations are interconnected with each other through projections, which contain synapses between two populations.\n\nANNarchy provides a set of classical neuron or synapse models, but also allows the definition of specific models. The ordinary differential equations (ODE) governing neural or synaptic dynamics have to be specified by the modeler. Contrary to other simulators (except Brian) which require to code these modules in a low-level language, ANNarchy provides a mathematical equation parser which can generate optimized C++ code depending on the chosen parallel framework. Bindings from C++ to Python are generated thanks to Cython (C-extensions to Python), which is a static compiler for Python. These bindings allow the Python script to access all data generated by the simulation (neuronal activity, connection weights) as if they were simple Python attributes. However, the simulation itself is independent from Python and its relatively low performance.\n\n### Example of a pulse-coupled network of Izhikevich neurons\n\nTo demonstrate the simplicity of ANNarchy's interface, let's focus on the \"Hello, World!\" of spiking networks: the pulse-coupled network of Izhikevich neurons (Izhikevich, 2003). It can be defined in ANNarchy as:\n\n```python\nfrom ANNarchy import *\n\n# Create the excitatory and inhibitory population\npop = Population(geometry=1000, neuron=Izhikevich)\nExc = pop[:800]                 ; Inh = pop[800:]\n\n# Set the population parameters\nre = np.random.random(800)      ; ri = np.random.random(200)\nExc.noise = 5.0                 ; Inh.noise = 2.0\nExc.a = 0.02                    ; Inh.a = 0.02 + 0.08 * ri\nExc.b = 0.2                     ; Inh.b = 0.25 - 0.05 * ri\nExc.c = -65.0 + 15.0 * re**2    ; Inh.c = -65.0\nExc.d = 8.0 - 6.0 * re**2       ; Inh.d = 2.0\nExc.v = -65.0                   ; Inh.v = -65.0\nExc.u = Exc.v * Exc.b           ; Inh.u = Inh.v * Inh.b\n\n# Create the projections\nexc_proj = Projection(pre=Exc, post=pop, target='exc')\nexc_proj.connect_all_to_all(weights=Uniform(0.0, 0.5))\n\ninh_proj = Projection(pre=Inh, post=pop, target='inh')\ninh_proj.connect_all_to_all(weights=Uniform(0.0, 1.0))\n\n# Compile\ncompile()\n\n# Start recording the spikes in the network to produce the plots\nM = Monitor(pop, ['spike', 'v'])\n\n# Simulate 1 second\nsimulate(1000.0, measure_time=True)\n\n# Retrieve the spike recordings and the membrane potential\nspikes = M.get('spike')\nv = M.get('v')\n\n# Compute the raster plot\nt, n = M.raster_plot(spikes)\n\n# Compute the population firing rate\nfr = M.histogram(spikes)\n\n# Plot the results\nimport matplotlib.pyplot as plt\nax = plt.subplot(3,1,1)\nax.plot(t, n, 'b.', markersize=1.0)\nax = plt.subplot(3,1,2)\nax.plot(v[:, 15])\nax = plt.subplot(3,1,3)\nax.plot(fr)\nplt.show()\n```\n\n![](../img/izhikevich.png)\n\n\n### Related publications\n\nOliver Maith, Helge Ülo Dinkelbach, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022).\\\n**BOLD monitoring in the neural simulator ANNarchy.**\\\n*Frontiers in Neuroinformatics 16:790966*\\\n[doi:10.3389/fninf.2022.790966](https:doi.org/10.3389/fninf.2022.790966)\n\n  \nHelge Ülo Dinkelbach, Badr-Eddine Bouhlal, Julien Vitay, and Fred H. Hamker (2022).\\\n**Auto-selection of an optimal sparse matrix format in the neuro-simulator ANNarchy.**\\\n*Frontiers in Neuroinformatics 16:877945\\\n[doi:10.3389/fninf.2022.877945](https:doi.org/10.3389/fninf.2022.877945)\n\nHelge Ülo Dinkelbach, Julien Vitay, and Fred H. Hamker (2019).\\\n**Scalable simulation of rate-coded and spiking neural networks on shared memory systems.**\\\n*2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany.* \\\n[doi:10.32470/CCN.2019.1109-0](https:doi.org/10.32470/CCN.2019.1109-0)\n\nJulien Vitay, Helge Ülo Dinkelbach, and Fred H. Hamker (2015).\\\n**ANNarchy: a code generation approach to neural simulations on parallel hardware.**\\\n*Frontiers in Neuroinformatics 9:19*\\\n[doi:10.3389/fninf.2015.00019](https:doi.org/10.3389/fninf.2015.00019)\n\nHelge Ü. Dinkelbach, Julien Vitay, and Fred H. Hamker (2012).\\\n**Comparison of GPU- and CPU-implementations of mean-firing rate neural networks on parallel hardware.**\\\n*Network: Computation in Neural Systems 23(4)*\\\n[doi:10.3109/0954898X.2012.739292](https:doi.org/10.3109/0954898X.2012.739292)","srcMarkdownNoYaml":"\n\nNeuro-computational models are different from classical neural networks (deep learning) in many aspects:\n\n* The complexity of the neurons, whose activity is governed by one or several differential equations instead of a simple weighted sum.\n* The complexity and diversity of the learning rules (synaptic plasticity), compared to gradient descent.\n* The size of the networks needed to simulate significant parts of the brain.\n* The huge diversity of models, architectures, frameworks used by researchers in computational neuroscience.\n\nThe increasing size of such networks asks for efficient parallel simulations, using distributed systems (OpenMP, MPI) or GPUs (CUDA). However, computational neuroscientists cannot be expected to be also experts in parallel computing. There is a need for a general-purpose neuro-simulator, with an easy but flexible interface allowing to define a huge variety of models, but which is internally efficient and allows for fast parallel simulations on various hardwares.\n\nOver many years, we have developed **ANNarchy** (Artificial Neural Networks architect), a parallel simulator for distributed rate-coded or spiking neural networks. The definition of the models is made in Python, but the library generates optimized C++ code to actually run the simulation on parallel hardware, using either openMP or CUDA. The current stable version is 4.7 and is released under the GNU GPL v2 or later.\n\nThe code is available at:\n\n<https://github.com/ANNarchy/ANNarchy>\n\nThe documentation is available at:\n\n<https://annarchy.github.io>\n\n### Core principles\n\nANNarchy separates the description of a neural network from its simulation. The description is declared in a Python script, offering high flexibility and readability of the code, and allowing to use the huge ecosystem of scientific libraries available with Python (Numpy, Scipy, Matplotlib...). Using Python furthermore reduces the programming effort to a minimum, letting the modeller concentrate on network design and data analysis.\n\n![](../img/annarchy.svg)\n\nA neural network is defined as a collection of interconnected populations of neurons. Each population comprises a set of similar artificial neurons (rate-coded or spiking point-neurons), whose activity is ruled by one or many ordinary differential equations. The activity of a neuron depends on the activity of other neurons through synapses, whose strength can evolve with time depending on pre- or post-synaptic activities (synaptic plasticity). Populations are interconnected with each other through projections, which contain synapses between two populations.\n\nANNarchy provides a set of classical neuron or synapse models, but also allows the definition of specific models. The ordinary differential equations (ODE) governing neural or synaptic dynamics have to be specified by the modeler. Contrary to other simulators (except Brian) which require to code these modules in a low-level language, ANNarchy provides a mathematical equation parser which can generate optimized C++ code depending on the chosen parallel framework. Bindings from C++ to Python are generated thanks to Cython (C-extensions to Python), which is a static compiler for Python. These bindings allow the Python script to access all data generated by the simulation (neuronal activity, connection weights) as if they were simple Python attributes. However, the simulation itself is independent from Python and its relatively low performance.\n\n### Example of a pulse-coupled network of Izhikevich neurons\n\nTo demonstrate the simplicity of ANNarchy's interface, let's focus on the \"Hello, World!\" of spiking networks: the pulse-coupled network of Izhikevich neurons (Izhikevich, 2003). It can be defined in ANNarchy as:\n\n```python\nfrom ANNarchy import *\n\n# Create the excitatory and inhibitory population\npop = Population(geometry=1000, neuron=Izhikevich)\nExc = pop[:800]                 ; Inh = pop[800:]\n\n# Set the population parameters\nre = np.random.random(800)      ; ri = np.random.random(200)\nExc.noise = 5.0                 ; Inh.noise = 2.0\nExc.a = 0.02                    ; Inh.a = 0.02 + 0.08 * ri\nExc.b = 0.2                     ; Inh.b = 0.25 - 0.05 * ri\nExc.c = -65.0 + 15.0 * re**2    ; Inh.c = -65.0\nExc.d = 8.0 - 6.0 * re**2       ; Inh.d = 2.0\nExc.v = -65.0                   ; Inh.v = -65.0\nExc.u = Exc.v * Exc.b           ; Inh.u = Inh.v * Inh.b\n\n# Create the projections\nexc_proj = Projection(pre=Exc, post=pop, target='exc')\nexc_proj.connect_all_to_all(weights=Uniform(0.0, 0.5))\n\ninh_proj = Projection(pre=Inh, post=pop, target='inh')\ninh_proj.connect_all_to_all(weights=Uniform(0.0, 1.0))\n\n# Compile\ncompile()\n\n# Start recording the spikes in the network to produce the plots\nM = Monitor(pop, ['spike', 'v'])\n\n# Simulate 1 second\nsimulate(1000.0, measure_time=True)\n\n# Retrieve the spike recordings and the membrane potential\nspikes = M.get('spike')\nv = M.get('v')\n\n# Compute the raster plot\nt, n = M.raster_plot(spikes)\n\n# Compute the population firing rate\nfr = M.histogram(spikes)\n\n# Plot the results\nimport matplotlib.pyplot as plt\nax = plt.subplot(3,1,1)\nax.plot(t, n, 'b.', markersize=1.0)\nax = plt.subplot(3,1,2)\nax.plot(v[:, 15])\nax = plt.subplot(3,1,3)\nax.plot(fr)\nplt.show()\n```\n\n![](../img/izhikevich.png)\n\n\n### Related publications\n\nOliver Maith, Helge Ülo Dinkelbach, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022).\\\n**BOLD monitoring in the neural simulator ANNarchy.**\\\n*Frontiers in Neuroinformatics 16:790966*\\\n[doi:10.3389/fninf.2022.790966](https:doi.org/10.3389/fninf.2022.790966)\n\n  \nHelge Ülo Dinkelbach, Badr-Eddine Bouhlal, Julien Vitay, and Fred H. Hamker (2022).\\\n**Auto-selection of an optimal sparse matrix format in the neuro-simulator ANNarchy.**\\\n*Frontiers in Neuroinformatics 16:877945\\\n[doi:10.3389/fninf.2022.877945](https:doi.org/10.3389/fninf.2022.877945)\n\nHelge Ülo Dinkelbach, Julien Vitay, and Fred H. Hamker (2019).\\\n**Scalable simulation of rate-coded and spiking neural networks on shared memory systems.**\\\n*2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany.* \\\n[doi:10.32470/CCN.2019.1109-0](https:doi.org/10.32470/CCN.2019.1109-0)\n\nJulien Vitay, Helge Ülo Dinkelbach, and Fred H. Hamker (2015).\\\n**ANNarchy: a code generation approach to neural simulations on parallel hardware.**\\\n*Frontiers in Neuroinformatics 9:19*\\\n[doi:10.3389/fninf.2015.00019](https:doi.org/10.3389/fninf.2015.00019)\n\nHelge Ü. Dinkelbach, Julien Vitay, and Fred H. Hamker (2012).\\\n**Comparison of GPU- and CPU-implementations of mean-firing rate neural networks on parallel hardware.**\\\n*Network: Computation in Neural Systems 23(4)*\\\n[doi:10.3109/0954898X.2012.739292](https:doi.org/10.3109/0954898X.2012.739292)"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":false,"html-math-method":"katex","email-obfuscation":"none","output-file":"annarchy.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.554","csl":"../frontiers.csl","resources":["../CNAME"],"theme":["sandstone","../styles.scss"],"title":"ANNarchy (Artificial Neural Networks architect)"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}