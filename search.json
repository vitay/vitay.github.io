[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Successor Representations\n\n\n\n\n\nSuccessor representations (SR) attract a lot of attention these days, both in the neuroscientific and machine learning / deep RL communities. This post is intended to explain the main difference between SR and model-free / model-based RL algorithms and to point out its usefulness to understand goal-directed behavior.\n\n\n\n\n\nMay 8, 2019\n\n\nJulien Vitay\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research",
    "section": "",
    "text": "I develop with Helge Dinkelbach ANNarchy (Artificial Neural Networks architect), a parallel simulator for distributed rate-coded or spiking neural networks. The definition of the models is in Python, but the library generates optimized C++ code to actually run the simulation on parallel hardware, using either openMP or CUDA."
  },
  {
    "objectID": "research.html#neuroinformatics",
    "href": "research.html#neuroinformatics",
    "title": "Research",
    "section": "",
    "text": "I develop with Helge Dinkelbach ANNarchy (Artificial Neural Networks architect), a parallel simulator for distributed rate-coded or spiking neural networks. The definition of the models is in Python, but the library generates optimized C++ code to actually run the simulation on parallel hardware, using either openMP or CUDA."
  },
  {
    "objectID": "research.html#artificial-intelligence",
    "href": "research.html#artificial-intelligence",
    "title": "Research",
    "section": "Artificial Intelligence",
    "text": "Artificial Intelligence\n\nReservoir computing\n\n\nReservoir computing studies the dynamical properties of recurrently connected populations of neurons. Their rich dynamics allow to represent and learn complex tasks currently out of reach of the classical machine learning methods, but also allow to better understand brain activities.\n\n\n\n\n\n\nDeep reinforcement learning\n\n\nReinforcement Learning (RL) is a machine learning framework studying how to derive optimal policies from reward signals. Coupled with deep neural networks, it became the most promising approach to general artificial intelligence.\n\n\n\n\n\n\nGeometric deep learning\n\n\nWhile deep learning approaches have been very successful with structured Euclidian data (image, sound, text), it is still very difficult to use them with non-Euclidian data such as graphs or 3D meshes. Within the ML@Karoprod project, we developed novel techniques allowing to leverage the speed and representational power of deep networks to accelerate the prediction of parameterized FEM simulations.\n\n\n\n\n\n\nCyber-security and anomaly detection\n\n\nComputer systems must be protected against cyber attacks from inside and outside. To guarantee faultless processing, the system must be monitored to detect problems and anomalous system behavior early enough. Anomaly detection methods can be applied to detect such events in a self-supervised manner. In the WAIKIKI project, we used a special kind of Tranformer, the Compact Convolutional Transformer (CCT), on project-specific log data in order to learn the distribution of valid log tokens and detect anomalies."
  },
  {
    "objectID": "research.html#computational-neuroscience",
    "href": "research.html#computational-neuroscience",
    "title": "Research",
    "section": "Computational neuroscience",
    "text": "Computational neuroscience\n\nBasal Ganglia\n\n\nThe Basal Ganglia (BG) are a set of nuclei located in the basal forebrain, receiving inputs mostly from the cerebral cortex and projecting to various motor centers, as well as back to the cortex through the thalamus, forming a closed-loop. It is involved in major functions such as reinforcement learning, habit formation, planning and motor control, but also in diseases such as Parkinson’s disease or Tourette syndrome.\n\n\n\n\n\n\nDopaminergic system\n\n\nThe dopaminergic system is composed of the ventral tegmental area (VTA) and the substantia nigra pars compacta (SNc). The neurotransmitter dopamine (DA) released by neurons in these two small areas exerts a strong influence on neural excitability and plasticity in many brain areas: mostly the basal ganglia (BG), but also the prefrontal cortex, the hippocampus or the amygdala.\n\n\n\n\n\n\nHippocampus\n\n\nThe hippocampus is a key structure for episodic memory and spatial navigation. A fundamental step in hippocampus research was the discovery of place cells, which fire whenever an animal traverses a certain location known as the place field (O’Keefe and Nadel, 1978). At rest, place cells exhibit brief periods of fast oscillations termed sharp wave-ripples. During these events, place cell activity shows sequential patterns called forward replay and reverse replay: time-compressed, and sometimes time-reversed, reproductions of previously experienced sequences. Spatial experiences stored in the hippocampus can therefore be recalled at will during behavior."
  },
  {
    "objectID": "research/reinforcementlearning.html",
    "href": "research/reinforcementlearning.html",
    "title": "Deep reinforcement learning",
    "section": "",
    "text": "Deep reinforcement learning (deep RL) is the integration of deep learning methods, classically used in supervised or unsupervised learning contexts, with reinforcement learning (RL), a well-studied adaptive control method used in problems with delayed and partial feedback.\n\n\n\n\n\nSee the complete course on deep reinforcement learning here:\nhttps://julien-vitay.net/course-deeprl/\nA free textbook on deep reinforcement learning is available here:\nhttps://julien-vitay.net/deeprl/\n\nRelated publications\nWinfried Lötzsch, Julien Vitay, and Fred H. Hamker (2017).\nTraining a deep policy gradient-based neural network with asynchronous learners on a simulated robotic problem.\nIn: Eibl, M. & Gaedke, M. (Eds.), INFORMATIK 2017. Gesellschaft für Informatik, Bonn. (S. 2143-2154)\ndoi:10.18420/in2017_214"
  },
  {
    "objectID": "research/annarchy.html",
    "href": "research/annarchy.html",
    "title": "ANNarchy (Artificial Neural Networks architect)",
    "section": "",
    "text": "Neuro-computational models are different from classical neural networks (deep learning) in many aspects:\n\nThe complexity of the neurons, whose activity is governed by one or several differential equations instead of a simple weighted sum.\nThe complexity and diversity of the learning rules (synaptic plasticity), compared to gradient descent.\nThe size of the networks needed to simulate significant parts of the brain.\nThe huge diversity of models, architectures, frameworks used by researchers in computational neuroscience.\n\nThe increasing size of such networks asks for efficient parallel simulations, using distributed systems (OpenMP, MPI) or GPUs (CUDA). However, computational neuroscientists cannot be expected to be also experts in parallel computing. There is a need for a general-purpose neuro-simulator, with an easy but flexible interface allowing to define a huge variety of models, but which is internally efficient and allows for fast parallel simulations on various hardwares.\nOver many years, we have developed ANNarchy (Artificial Neural Networks architect), a parallel simulator for distributed rate-coded or spiking neural networks. The definition of the models is made in Python, but the library generates optimized C++ code to actually run the simulation on parallel hardware, using either openMP or CUDA. The current stable version is 4.7 and is released under the GNU GPL v2 or later.\nThe code is available at:\nhttps://github.com/ANNarchy/ANNarchy\nThe documentation is available at:\nhttps://annarchy.github.io\n\nCore principles\nANNarchy separates the description of a neural network from its simulation. The description is declared in a Python script, offering high flexibility and readability of the code, and allowing to use the huge ecosystem of scientific libraries available with Python (Numpy, Scipy, Matplotlib…). Using Python furthermore reduces the programming effort to a minimum, letting the modeller concentrate on network design and data analysis.\n\nA neural network is defined as a collection of interconnected populations of neurons. Each population comprises a set of similar artificial neurons (rate-coded or spiking point-neurons), whose activity is ruled by one or many ordinary differential equations. The activity of a neuron depends on the activity of other neurons through synapses, whose strength can evolve with time depending on pre- or post-synaptic activities (synaptic plasticity). Populations are interconnected with each other through projections, which contain synapses between two populations.\nANNarchy provides a set of classical neuron or synapse models, but also allows the definition of specific models. The ordinary differential equations (ODE) governing neural or synaptic dynamics have to be specified by the modeler. Contrary to other simulators (except Brian) which require to code these modules in a low-level language, ANNarchy provides a mathematical equation parser which can generate optimized C++ code depending on the chosen parallel framework. Bindings from C++ to Python are generated thanks to Cython (C-extensions to Python), which is a static compiler for Python. These bindings allow the Python script to access all data generated by the simulation (neuronal activity, connection weights) as if they were simple Python attributes. However, the simulation itself is independent from Python and its relatively low performance.\n\n\nExample of a pulse-coupled network of Izhikevich neurons\nTo demonstrate the simplicity of ANNarchy’s interface, let’s focus on the “Hello, World!” of spiking networks: the pulse-coupled network of Izhikevich neurons (Izhikevich, 2003). It can be defined in ANNarchy as:\nfrom ANNarchy import *\n\n# Create the excitatory and inhibitory population\npop = Population(geometry=1000, neuron=Izhikevich)\nExc = pop[:800]                 ; Inh = pop[800:]\n\n# Set the population parameters\nre = np.random.random(800)      ; ri = np.random.random(200)\nExc.noise = 5.0                 ; Inh.noise = 2.0\nExc.a = 0.02                    ; Inh.a = 0.02 + 0.08 * ri\nExc.b = 0.2                     ; Inh.b = 0.25 - 0.05 * ri\nExc.c = -65.0 + 15.0 * re**2    ; Inh.c = -65.0\nExc.d = 8.0 - 6.0 * re**2       ; Inh.d = 2.0\nExc.v = -65.0                   ; Inh.v = -65.0\nExc.u = Exc.v * Exc.b           ; Inh.u = Inh.v * Inh.b\n\n# Create the projections\nexc_proj = Projection(pre=Exc, post=pop, target='exc')\nexc_proj.connect_all_to_all(weights=Uniform(0.0, 0.5))\n\ninh_proj = Projection(pre=Inh, post=pop, target='inh')\ninh_proj.connect_all_to_all(weights=Uniform(0.0, 1.0))\n\n# Compile\ncompile()\n\n# Start recording the spikes in the network to produce the plots\nM = Monitor(pop, ['spike', 'v'])\n\n# Simulate 1 second\nsimulate(1000.0, measure_time=True)\n\n# Retrieve the spike recordings and the membrane potential\nspikes = M.get('spike')\nv = M.get('v')\n\n# Compute the raster plot\nt, n = M.raster_plot(spikes)\n\n# Compute the population firing rate\nfr = M.histogram(spikes)\n\n# Plot the results\nimport matplotlib.pyplot as plt\nax = plt.subplot(3,1,1)\nax.plot(t, n, 'b.', markersize=1.0)\nax = plt.subplot(3,1,2)\nax.plot(v[:, 15])\nax = plt.subplot(3,1,3)\nax.plot(fr)\nplt.show()\n\n\n\nRelated publications\nOliver Maith, Helge Ülo Dinkelbach, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022).\nBOLD monitoring in the neural simulator ANNarchy.\nFrontiers in Neuroinformatics 16:790966\ndoi:10.3389/fninf.2022.790966\nHelge Ülo Dinkelbach, Badr-Eddine Bouhlal, Julien Vitay, and Fred H. Hamker (2022).\nAuto-selection of an optimal sparse matrix format in the neuro-simulator ANNarchy.\n*Frontiers in Neuroinformatics 16:877945\ndoi:10.3389/fninf.2022.877945\nHelge Ülo Dinkelbach, Julien Vitay, and Fred H. Hamker (2019).\nScalable simulation of rate-coded and spiking neural networks on shared memory systems.\n2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany.\ndoi:10.32470/CCN.2019.1109-0\nJulien Vitay, Helge Ülo Dinkelbach, and Fred H. Hamker (2015).\nANNarchy: a code generation approach to neural simulations on parallel hardware.\nFrontiers in Neuroinformatics 9:19\ndoi:10.3389/fninf.2015.00019\nHelge Ü. Dinkelbach, Julien Vitay, and Fred H. Hamker (2012).\nComparison of GPU- and CPU-implementations of mean-firing rate neural networks on parallel hardware.\nNetwork: Computation in Neural Systems 23(4)\ndoi:10.3109/0954898X.2012.739292"
  },
  {
    "objectID": "research/basalganglia.html",
    "href": "research/basalganglia.html",
    "title": "Basal Ganglia",
    "section": "",
    "text": "The Basal Ganglia (BG) are a set of nuclei located in the basal forebrain, receiving inputs mostly from the cerebral cortex (especially the frontal lobe) and projecting on various motor centers, as well as back to the cortex through the thalamus, forming a closed-loop.\nThe main input station is the striatum, which can be anatomically divided into three parts: the nucleus accumbens (NAcc), the caudate nucleus (CN) and the putamen (PUT). Striatal neurons are excited by cortical activity and inhibit in turn the tonically active neurons of the output nuclei of the BG: the substantia nigra pars reticulata (SNr) and the internal segment of the globus pallidus (GPi). These output structures further inhibit some motor centers and thalamic nuclei.\n\nThis double inhibition allows to selectively open some recurrent loops between the thalamus and the cortex, increasing the signal-to-noise ratio in the cortex and triggering movements or cognitive functions.\nOther nuclei in the BG, such as the subthalamic nucleus (STN) and the external part of the globus pallidus (GPe), create functionally different pathways to allow for a more complex role of BG in adapting behavior.\nThe main characteristic of the BG is its dense innervation by dopaminergic (DA) cells in the substantia nigra pars compacta (SNc) and ventral tegmental area (VTA), whose firing is related to reward delivery and prediction. DA can modulate the activation and learning of most cells in the BG, placing it as a core structure in reinforcement learning processes.\n\nRelated publications\nCarolin Scholl, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022).\nEnhanced Habit Formation in Tourette Patients Explained by Shortcut Modulation in a Hierarchical Cortico-Basal Ganglia Model.\nBrain Structure and Function 227, 1031-1050\ndoi:10.1007/s00429-021-02446-x\nFrancesc Villagrasa, Javier Baladron, Julien Vitay, Henning Schroll, Evan G. Antzoulatos, Earl K. Miller, and Fred H. Hamker (2018).\nOn the role of cortex-basal ganglia interactions for category learning: A neuro-computational approach.\nJournal of Neuroscience 38(44) 9551-9562\ndoi:10.1523/JNEUROSCI.0874-18.2018\nHenning Schroll, Julien Vitay, and Fred H. Hamker (2014).\nDysfunctional and compensatory synaptic plasticity in Parkinson’s disease.\nEuropean Journal of Neuroscience, 39: 688-702\ndoi:10.1111/ejn.12434\nHenning Schroll, Julien Vitay, and Fred H. Hamker (2012).\nWorking memory and response selection: A computational account of interactions among cortico-basalganglio-thalamic loops.\nNeural Networks, 26\ndoi:10.1016/j.neunet.2011.10.008\nJulien Vitay and Fred H. Hamker (2012).\nBasal Ganglia learning.\nIn Encyclopedia of the Sciences of Learning. Seel, Norbert M. (Ed.).\ndoi:10.1007/978-1-4419-1428-6\nJulien Vitay and Fred H. Hamker (2010).\nA computational model of basal ganglia and its role in memory retrieval in rewarded visual memory tasks.\nFrontiers in Computational Neuroscience 4(13)\ndoi:10.3389/fncom.2010.00013"
  },
  {
    "objectID": "research/dopamine.html",
    "href": "research/dopamine.html",
    "title": "Dopaminergic system",
    "section": "",
    "text": "The dopaminergic system is composed of the ventral tegmental area (VTA) and the substantia nigra pars compacta (SNc). The neurotransmitter dopamine (DA) released by neurons in these two small areas exerts a strong influence on neural excitability and plasticity in many brain areas: mostly the basal ganglia (BG), but also the prefrontal cortex, the hippocampus or the amygdala.\nA striking feature of VTA cells is their response during classical (or Pavlovian) conditioning, as observed by Schultz et al (1998). Early on, VTA cells respond phasically (a burst) to unconditioned stimuli (US, or rewards in operant conditioning). Gradually during learning, the amplitude of this response decreases, replaced by a response to the conditioned stimuli (CS) which are predictive of reward delivery. Moreover, if a reward is predicted by the CS but omitted, VTA cells show a brief depression of activity (a dip) at the time where the US was expected. This pattern resembles the temporal difference (TD) error signal used in reinforcement learning, what generated multitudes of models based on that analogy.\n\nWhat remains unclear is how VTA cells access information about the US, the CS and more importantly the time elapsed since CS onset. The goal of this research project is to investigate the mechanisms by which VTA is able to exhibit these properties, by looking at the afferent system to VTA. VTa indeed receives information from many brain areas, either directly as the rostromedial tegmental area (RMTg), the pedunculopontine nucleus (PPTN) or the nucleus accumbens (NAcc), or indirectly as the amygdala, the lateral habenula (LHb), the ventral pallidum (VP) or the ventromedial prefrontal cortex (vmPFC).\n\nRelated publications\nJulien Vitay (2017).\nOn the role of dopamine in motivated behavior: a neuro-computational approach.\nHabilitation (Technische Universität Chemnitz).\n\nJulien Vitay and Fred H. Hamker (2014).\nTiming and expectation of reward: a neuro-computational model of the afferents to the ventral tegmental area.\nFrontiers in Neurorobotics. 8:4\ndoi:10.3389/fnbot.2014.00004\nJulien Vitay and Fred H. Hamker (2007).\nOn the role of dopamine in cognitive vision.\nIn: Paletta, L., Rome, E. (eds) Attention in Cognitive Systems. Theories and Systems from an Interdisciplinary Viewpoint. WAPCV 2007. Lecture Notes in Computer Science(), vol 4840. Springer, Berlin, Heidelberg\ndoi:10.1007/978-3-540-77343-6_23"
  },
  {
    "objectID": "research/reservoircomputing.html",
    "href": "research/reservoircomputing.html",
    "title": "Reservoir computing",
    "section": "",
    "text": "The field of reservoir computing, covering Echo-State Networks (ESN; Jaeger, 2000) and Liquid State Machines (Maas, 2001), studies the dynamical properties of recurrent neural networks. Depending on the strength of the recurrent connections, the reservoirs can exhibit either deterministic or chaotic trajectories following a stimulation.\n\nThese trajectories can serve as a complex temporal basis to represent events. In their early formulation, reservoirs were fixed and read-out neurons used this basis to mimic specific target signals using supervised learning.\nIn the recent years, methods have been developed to train the connections inside the reservoir too, either using supervised learning (e.g. Laje and Buonomano 2013) or reinforcement learning (Miconi, 2017). This unleashes the potential of reservoirs for both machine learning applications and computational neuroscience.\nWe study the properties of reservoir computing at the neuroscientific level, with an emphasis on reinforcement learning, forward models in the cerebellum (Schmid et al, 2019) or interval timing.\n\nRelated publications\nKatharina Schmid, Julien Vitay, and Fred H. Hamker (2019).\nForward Models in the Cerebellum using Reservoirs and Perturbation Learning.\n2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany\ndoi:10.32470/CCN.2019.1139-0\nJulien Vitay (2016).\n[Re] Robust timing and motor patterns by taming chaos in recurrent neural networks.\nRescience, 2(1)\ndoi:10.5281/zenodo.159545"
  },
  {
    "objectID": "datenschutz.html",
    "href": "datenschutz.html",
    "title": "Datenschutzerklärung",
    "section": "",
    "text": "Die verantwortliche Stelle für die Datenverarbeitung auf dieser Website ist:\nJulien Vitay\nStraße der Nationen 62\n09107 Chemnitz\nDie verantwortliche Stelle entscheidet allein oder gemeinsam mit anderen über die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten (z.B. Namen, Kontaktdaten o. Ä.).\n\n\n\n\nNur mit Ihrer ausdrücklichen Einwilligung sind einige Vorgänge der Datenverarbeitung möglich. Ein Widerruf Ihrer bereits erteilten Einwilligung ist jederzeit möglich. Für den Widerruf genügt eine formlose Mitteilung per E-Mail. Die Rechtmäßigkeit der bis zum Widerruf erfolgten Datenverarbeitung bleibt vom Widerruf unberührt.\n\n\n\nAls Betroffener steht Ihnen im Falle eines datenschutzrechtlichen Verstoßes ein Beschwerderecht bei der zuständigen Aufsichtsbehörde zu. Zuständige Aufsichtsbehörde bezüglich datenschutzrechtlicher Fragen ist der Landesdatenschutzbeauftragte des Bundeslandes, in dem sich der Sitz unseres Unternehmens befindet. Der folgende Link stellt eine Liste der Datenschutzbeauftragten sowie deren Kontaktdaten bereit: https://www.bfdi.bund.de/DE/Infothek/Anschriften_Links/anschriften_links-node.html.\n\n\n\nIhnen steht das Recht zu, Daten, die wir auf Grundlage Ihrer Einwilligung oder in Erfüllung eines Vertrags automatisiert verarbeiten, an sich oder an Dritte aushändigen zu lassen. Die Bereitstellung erfolgt in einem maschinenlesbaren Format. Sofern Sie die direkte Übertragung der Daten an einen anderen Verantwortlichen verlangen, erfolgt dies nur, soweit es technisch machbar ist.\n\n\n\nSie haben jederzeit im Rahmen der geltenden gesetzlichen Bestimmungen das Recht auf unentgeltliche Auskunft über Ihre gespeicherten personenbezogenen Daten, Herkunft der Daten, deren Empfänger und den Zweck der Datenverarbeitung und ggf. ein Recht auf Berichtigung, Sperrung oder Löschung dieser Daten. Diesbezüglich und auch zu weiteren Fragen zum Thema personenbezogene Daten können Sie sich jederzeit über die im Impressum aufgeführten Kontaktmöglichkeiten an uns wenden.\n\n\n\nAus Sicherheitsgründen und zum Schutz der Übertragung vertraulicher Inhalte, die Sie an uns als Seitenbetreiber senden, nutzt unsere Website eine SSL-bzw. TLS-Verschlüsselung. Damit sind Daten, die Sie über diese Website übermitteln, für Dritte nicht mitlesbar. Sie erkennen eine verschlüsselte Verbindung an der „https://“ Adresszeile Ihres Browsers und am Schloss-Symbol in der Browserzeile.\n\n\n\n\nWir verwenden Google Fonts von Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, als Dienst zur Bereitstellung von Schriftarten für unser Onlineangebot. Um diese Schriftarten zu beziehen, stellen Sie eine Verbindung zu Servern von Google Ireland Limited her, wobei Ihre IP-Adresse übertragen wird.\n\n\n\nDer Einsatz von Google Fonts erfolgt auf Grundlage Ihrer Einwilligung gemäß Art. 6 Abs. 1 lit. a. DSGVO und § 25 Abs. 1 TTDSG.\n\n\nWir beabsichtigen personenbezogenen Daten an Drittländer außerhalb des Europäischen Wirtschaftsraums, insbesondere die USA, zu übermitteln. In Fällen, in denen kein Angemessenheitsbeschluss der Europäischen Kommission existiert (z.B. in den USA) haben wir mit den Empfängern der Daten anderweitige geeignete Garantien im Sinne der Art. 44 ff. DSGVO vereinbart. Dies sind – sofern nicht anders angegeben – Standardvertragsklauseln der EU-Kommission gemäß Durchführungsbeschluss (EU) 2021/914 vom 4. Juni 2021. Eine Kopie dieser Standardvertragsklauseln können Sie unter https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:32021D0914&from=DE einsehen.\n\n\nZudem holen wir vor einem solchen Drittlandtransfer Ihre Einwilligung nach Art. 49 Abs. 1 Satz 1 lit. a. DSGVO ein, die Sie über die Einwilligung im Consent Manager (oder sonstigen Formularen, Registrierungen etc.) erteilen. Wir weisen Sie darauf hin, dass bei Drittlandübermittlungen im Detail unbekannte Risiken (z.B. die Datenverarbeitung durch Sicherheitsbehörden des Drittlandes, deren genauer Umfang und deren Folgen für Sie wir nicht kennen, auf die wir keinen Einfluss haben und von denen Sie unter Umständen keine Kenntnis erlangen) bestehen können.\n\n\n\nDie konkrete Speicherdauer der verarbeiteten Daten ist nicht durch uns beeinflussbar, sondern wird von Google Ireland Limited bestimmt. Weitere Hinweise finden Sie in der Datenschutzerklärung für Google Fonts: https://policies.google.com/privacy.\n\n\n\n\nWir verwenden zur ordnungsgemäßen Bereitstellung der Inhalte unserer Website Font Awesome des Anbieters Fonticons, Inc..\n\n\n\nDer Einsatz von Font Awesome erfolgt auf Grundlage Ihrer Einwilligung gemäß Art. 6 Abs. 1 lit. a. DSGVO und § 25 Abs. 1 TTDSG.\n\n\nWir beabsichtigen personenbezogenen Daten an Drittländer außerhalb des Europäischen Wirtschaftsraums, insbesondere die USA, zu übermitteln. In Fällen, in denen kein Angemessenheitsbeschluss der Europäischen Kommission existiert (z.B. in den USA) haben wir mit den Empfängern der Daten anderweitige geeignete Garantien im Sinne der Art. 44 ff. DSGVO vereinbart. Dies sind – sofern nicht anders angegeben – Standardvertragsklauseln der EU-Kommission gemäß Durchführungsbeschluss (EU) 2021/914 vom 4. Juni 2021. Eine Kopie dieser Standardvertragsklauseln können Sie unter https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:32021D0914&from=DE einsehen.\n\n\nZudem holen wir vor einem solchen Drittlandtransfer Ihre Einwilligung nach Art. 49 Abs. 1 Satz 1 lit. a. DSGVO ein, die Sie über die Einwilligung im Consent Manager (oder sonstigen Formularen, Registrierungen etc.) erteilen. Wir weisen Sie darauf hin, dass bei Drittlandübermittlungen im Detail unbekannte Risiken (z.B. die Datenverarbeitung durch Sicherheitsbehörden des Drittlandes, deren genauer Umfang und deren Folgen für Sie wir nicht kennen, auf die wir keinen Einfluss haben und von denen Sie unter Umständen keine Kenntnis erlangen) bestehen können.\n\n\n\nDie konkrete Speicherdauer der verarbeiteten Daten ist nicht durch uns beeinflussbar, sondern wird von Fonticons, Inc. bestimmt. Weitere Hinweise finden Sie in der Datenschutzerklärung für Font Awesome CDN: https://cdn.fontawesome.com/privacy.\n\n\nQuelle: Datenschutz-Konfigurator von Mein-Datenschutzbeauftragter.de"
  },
  {
    "objectID": "datenschutz.html#allgemeiner-hinweis-und-pflichtinformationen",
    "href": "datenschutz.html#allgemeiner-hinweis-und-pflichtinformationen",
    "title": "Datenschutzerklärung",
    "section": "",
    "text": "Die verantwortliche Stelle für die Datenverarbeitung auf dieser Website ist:\nJulien Vitay\nStraße der Nationen 62\n09107 Chemnitz\nDie verantwortliche Stelle entscheidet allein oder gemeinsam mit anderen über die Zwecke und Mittel der Verarbeitung von personenbezogenen Daten (z.B. Namen, Kontaktdaten o. Ä.).\n\n\n\n\nNur mit Ihrer ausdrücklichen Einwilligung sind einige Vorgänge der Datenverarbeitung möglich. Ein Widerruf Ihrer bereits erteilten Einwilligung ist jederzeit möglich. Für den Widerruf genügt eine formlose Mitteilung per E-Mail. Die Rechtmäßigkeit der bis zum Widerruf erfolgten Datenverarbeitung bleibt vom Widerruf unberührt.\n\n\n\nAls Betroffener steht Ihnen im Falle eines datenschutzrechtlichen Verstoßes ein Beschwerderecht bei der zuständigen Aufsichtsbehörde zu. Zuständige Aufsichtsbehörde bezüglich datenschutzrechtlicher Fragen ist der Landesdatenschutzbeauftragte des Bundeslandes, in dem sich der Sitz unseres Unternehmens befindet. Der folgende Link stellt eine Liste der Datenschutzbeauftragten sowie deren Kontaktdaten bereit: https://www.bfdi.bund.de/DE/Infothek/Anschriften_Links/anschriften_links-node.html.\n\n\n\nIhnen steht das Recht zu, Daten, die wir auf Grundlage Ihrer Einwilligung oder in Erfüllung eines Vertrags automatisiert verarbeiten, an sich oder an Dritte aushändigen zu lassen. Die Bereitstellung erfolgt in einem maschinenlesbaren Format. Sofern Sie die direkte Übertragung der Daten an einen anderen Verantwortlichen verlangen, erfolgt dies nur, soweit es technisch machbar ist.\n\n\n\nSie haben jederzeit im Rahmen der geltenden gesetzlichen Bestimmungen das Recht auf unentgeltliche Auskunft über Ihre gespeicherten personenbezogenen Daten, Herkunft der Daten, deren Empfänger und den Zweck der Datenverarbeitung und ggf. ein Recht auf Berichtigung, Sperrung oder Löschung dieser Daten. Diesbezüglich und auch zu weiteren Fragen zum Thema personenbezogene Daten können Sie sich jederzeit über die im Impressum aufgeführten Kontaktmöglichkeiten an uns wenden.\n\n\n\nAus Sicherheitsgründen und zum Schutz der Übertragung vertraulicher Inhalte, die Sie an uns als Seitenbetreiber senden, nutzt unsere Website eine SSL-bzw. TLS-Verschlüsselung. Damit sind Daten, die Sie über diese Website übermitteln, für Dritte nicht mitlesbar. Sie erkennen eine verschlüsselte Verbindung an der „https://“ Adresszeile Ihres Browsers und am Schloss-Symbol in der Browserzeile.\n\n\n\n\nWir verwenden Google Fonts von Google Ireland Limited, Gordon House, Barrow Street, Dublin 4, Irland, als Dienst zur Bereitstellung von Schriftarten für unser Onlineangebot. Um diese Schriftarten zu beziehen, stellen Sie eine Verbindung zu Servern von Google Ireland Limited her, wobei Ihre IP-Adresse übertragen wird.\n\n\n\nDer Einsatz von Google Fonts erfolgt auf Grundlage Ihrer Einwilligung gemäß Art. 6 Abs. 1 lit. a. DSGVO und § 25 Abs. 1 TTDSG.\n\n\nWir beabsichtigen personenbezogenen Daten an Drittländer außerhalb des Europäischen Wirtschaftsraums, insbesondere die USA, zu übermitteln. In Fällen, in denen kein Angemessenheitsbeschluss der Europäischen Kommission existiert (z.B. in den USA) haben wir mit den Empfängern der Daten anderweitige geeignete Garantien im Sinne der Art. 44 ff. DSGVO vereinbart. Dies sind – sofern nicht anders angegeben – Standardvertragsklauseln der EU-Kommission gemäß Durchführungsbeschluss (EU) 2021/914 vom 4. Juni 2021. Eine Kopie dieser Standardvertragsklauseln können Sie unter https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:32021D0914&from=DE einsehen.\n\n\nZudem holen wir vor einem solchen Drittlandtransfer Ihre Einwilligung nach Art. 49 Abs. 1 Satz 1 lit. a. DSGVO ein, die Sie über die Einwilligung im Consent Manager (oder sonstigen Formularen, Registrierungen etc.) erteilen. Wir weisen Sie darauf hin, dass bei Drittlandübermittlungen im Detail unbekannte Risiken (z.B. die Datenverarbeitung durch Sicherheitsbehörden des Drittlandes, deren genauer Umfang und deren Folgen für Sie wir nicht kennen, auf die wir keinen Einfluss haben und von denen Sie unter Umständen keine Kenntnis erlangen) bestehen können.\n\n\n\nDie konkrete Speicherdauer der verarbeiteten Daten ist nicht durch uns beeinflussbar, sondern wird von Google Ireland Limited bestimmt. Weitere Hinweise finden Sie in der Datenschutzerklärung für Google Fonts: https://policies.google.com/privacy.\n\n\n\n\nWir verwenden zur ordnungsgemäßen Bereitstellung der Inhalte unserer Website Font Awesome des Anbieters Fonticons, Inc..\n\n\n\nDer Einsatz von Font Awesome erfolgt auf Grundlage Ihrer Einwilligung gemäß Art. 6 Abs. 1 lit. a. DSGVO und § 25 Abs. 1 TTDSG.\n\n\nWir beabsichtigen personenbezogenen Daten an Drittländer außerhalb des Europäischen Wirtschaftsraums, insbesondere die USA, zu übermitteln. In Fällen, in denen kein Angemessenheitsbeschluss der Europäischen Kommission existiert (z.B. in den USA) haben wir mit den Empfängern der Daten anderweitige geeignete Garantien im Sinne der Art. 44 ff. DSGVO vereinbart. Dies sind – sofern nicht anders angegeben – Standardvertragsklauseln der EU-Kommission gemäß Durchführungsbeschluss (EU) 2021/914 vom 4. Juni 2021. Eine Kopie dieser Standardvertragsklauseln können Sie unter https://eur-lex.europa.eu/legal-content/DE/TXT/HTML/?uri=CELEX:32021D0914&from=DE einsehen.\n\n\nZudem holen wir vor einem solchen Drittlandtransfer Ihre Einwilligung nach Art. 49 Abs. 1 Satz 1 lit. a. DSGVO ein, die Sie über die Einwilligung im Consent Manager (oder sonstigen Formularen, Registrierungen etc.) erteilen. Wir weisen Sie darauf hin, dass bei Drittlandübermittlungen im Detail unbekannte Risiken (z.B. die Datenverarbeitung durch Sicherheitsbehörden des Drittlandes, deren genauer Umfang und deren Folgen für Sie wir nicht kennen, auf die wir keinen Einfluss haben und von denen Sie unter Umständen keine Kenntnis erlangen) bestehen können.\n\n\n\nDie konkrete Speicherdauer der verarbeiteten Daten ist nicht durch uns beeinflussbar, sondern wird von Fonticons, Inc. bestimmt. Weitere Hinweise finden Sie in der Datenschutzerklärung für Font Awesome CDN: https://cdn.fontawesome.com/privacy.\n\n\nQuelle: Datenschutz-Konfigurator von Mein-Datenschutzbeauftragter.de"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Dr. Julien Vitay",
    "section": "",
    "text": "Researcher / lecturer in Artificial Intelligence."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Dr. Julien Vitay",
    "section": "Education",
    "text": "Education\n   Habilitation in Computer Science 2017\n\\rightarrow Chemnitz University of Technology, Germany.\n   Ph.D. in Computer Science 2006\n\\rightarrow Université Henri Poincaré Nancy-I, France.\n   Engineering degree in Signal Processing and Microelectronics 2002\n\\rightarrow École Supérieure d’Électricité (Supélec), Rennes, France.\n   Master of Science in Microelectronics 2002\n\\rightarrow Université Rennes-I, France."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Dr. Julien Vitay",
    "section": "Experience",
    "text": "Experience\n   eOdyn - France 2025 - now\n\\rightarrow AI researcher and lead Data Scientist at eOdyn in Plouzané / Brest.\n\nPrediction of oceanic currents based on AIS data.\nAnomaly detection in AIS signals.\n\n\n   Chemnitz University of Technology - Germany 2011 - 2025\n\\rightarrow Researcher / lecturer in the faculty of Computer science, AI lab of Fred Hamker.\n\nResearch:\n\nNeuroinformatics: neurosimulator ANNarchy.\nDeep reinforcement learning.\nReservoir computing.\nComputational neuroscience: basal ganglia, dopamine, hippocampus.\n\nTeaching:\n\nNeurocomputing / Machine Learning\nDeep Reinforcement Learning\nComputer Vision\nIntroduction to AI.\n\nErasmus+ departmental coordinator.\n\n\n   WWU University of Münster - Germany 2006 - 2011\n\\rightarrow Postdoc in the Institute of Psychology, lab of Markus Lappe, supervisor Fred Hamker.\n\nResearch:\n\nComputational neuroscience: basal ganglia.\n\n\n\n   Inria Lorraine - France 2002 - 2006\n\\rightarrow PhD student in the Cortex team (LORIA Nancy), supervisors Frédéric Alexandre and Nicolas Rougier (now in Mnemosyne).\n\nResearch:\n\nComputational neuroscience: basal ganglia, visual attention.\nRobotics.\n\nTeaching (at the University of Nancy-I):\n\nComputer architecture, Java, AI."
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "Dr. Julien Vitay",
    "section": "Skills",
    "text": "Skills\n   Programming languages: Python, C++, C, Java, Matlab, Julia\n   Machine learning frameworks: pytorch, tensorflow, scikit-learn, XGBoost, rllib, tianshou, mlflow\n   Parallel computing: OpenMP, MPI, CUDA"
  },
  {
    "objectID": "about.html#third-party-projects",
    "href": "about.html#third-party-projects",
    "title": "Dr. Julien Vitay",
    "section": "Third-party projects",
    "text": "Third-party projects\n\n\n\n\n\n\nEU CAVAA 2022 - 2026\n\n\n\n\n\nTitle: Counterfactual Assessment and Valuation for Awareness Architecture.\nPartners: Radboud University, TU Chemnitz, CERTH, Sorbonne Université, Eodyne Systems, University of Sheffield, Robotnik Automation, University of Oxford, Uppsala University, tp21 GmbH.\nRole: Research.\n\n\n\n\n\n\n\n\n\nBMBF Smart AirSense (01IS22026A) 2022 - 2024\n\n\n\n\n\nTitle: Erforschung von KI Methoden zur Entwicklung eines interaktiven Gesundheitsassistenten auf Basis von Human in the Loop Machine Learning.\n→ Research on AI methods for the development of an interactive health assistant based on human-in-the-loop machine learning.\nPartners: Corant GmbH, TU Chemnitz.\nRole: Design, co-supervision of Aida Farahani and Payam Atoofi.\n\n\n\n\n\n\n\n\n\nBMBF WAIKIKI (16KIS1199) 2020 - 2023\n\n\n\n\n\nTitle: Wissensbasierte Anomalieerkennung mittels Künstlicher Intelligenz in Kritischen Infrastrukturen.\n→ Knowledge-based anomaly detection using artificial intelligence in critical infrastructures.\nPartners: TU Cottbus, TU Chemnitz, LEAG, RWE AG, STEAG GmbH, ASCORI GmbH, migosens GmbH, ZEDAS GmbH.\nRole: Design, co-supervision of René Larisch.\n\n\n\n\n\n\n\n\n\nBMBF ML@Karoprod (01IS18055C) 2018 - 2021\n\n\n\n\n\nTitle: Maschinelles Lernen zur Prognose von Prozessparametern und Bauteilqualität in der automobilen Karosserieproduktion.\n→ Machine learning for the prediction of process parameters and component quality in automotive body production.\nPartners: Fraunhofer IWU Dresden, Scale GmbH, TU Chemnitz.\nRole: Design, research, co-supervision of Aida Farahani and Payam Atoofi.\n\n\n\n\n\n\n\n\n\nDFG grant (HA2630/9-1) 2016 - 2019\n\n\n\n\n\nTitle: Auto-tuning for neural simulations on different parallel hardware.\nPartners: TU Chemnitz (Hamker).\nRole: Design, co-supervision of Helge Dinkelbach.\n\n\n\n\n\n\n\n\n\nESF project Helplessness 2016 - 2019\n\n\n\n\n\nTitle: Sozial agierende, kognitive Systeme zur Feststellung von Hilfsbedürftigkeit.\n→ Social, active and cognitive systems for the detection of helplessness\nPartners: TU Chemnitz.\nRole: Principal Investigator\n\n\n\n\n\n\n\n\n\nBMBF Macelot (16SV7260) 2015 - 2018\n\n\n\n\n\nTitle: StayCentered - Methodenbasis eines Assistenzsystems für Centerlotsen - MACeLot.\n→ Method base of an assistance system for center pilots\nPartners: TU Chemnitz.\nRole: Research.\n\n\n\n\n\n\n\n\n\nDFG graduate school Crossworlds (GRK 1780) 2012 - 2016\n\n\n\n\n\nTitle: CrossWorlds: Kopplung virtueller und realer sozialer Welten\n→ CrossWorlds: Coupling virtual and real social worlds.\nPartners: TU Chemnitz.\nRole: Principal investigator.\n\n\n\n\n\n\n\n\n\nDFG grant (HA2630/4-2) 2011 - 2014\n\n\n\n\n\nTitle: The cognitive control of visual perception and action selection.\nPartners: TU Chemnitz (Hamker).\nRole: Research.\n\n\n\n\n\n\n\n\n\nDFG grant (HA2630/4-1) 2006 - 2009\n\n\n\n\n\nTitle: A systems approach to modeling the cognitive guidance of attention and object/category recognition.\nPartners: TU Chemnitz (Hamker).\nRole: Research (employed).\n\n\n\n\n\n\n\n\n\nEU Mirrorbot 2002 - 2005\n\n\n\n\n\nTitle: Biomimetic Multimodal Learning in a Mirror Neuron-based Robot.\nPartners: Sunderland, Inria, Parma, Cambridge, Ulm.\nRole: Research (employed)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Julien Vitay",
    "section": "",
    "text": "Dr. Julien Vitay\n\n\nAI Researcher / lead Data Scientist at eOdyn in Plouzané / Brest.\n\n\n\nArtificial Intelligence - Oceanography\n\n\n\n -  -  -  -  - \neOdyn SaS\nTechnopole Brest Iroise \n115, rue Claude Chappe \nF-29280 Plouzané\nFrance"
  },
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "Teaching",
    "section": "",
    "text": "Level: Master\nResponsability: Creation, lectures and exercises (until 2023)\nCourse materials: https://julien-vitay.net/course-neurocomputing"
  },
  {
    "objectID": "teaching.html#neurocomputing-machine-learning",
    "href": "teaching.html#neurocomputing-machine-learning",
    "title": "Teaching",
    "section": "",
    "text": "Level: Master\nResponsability: Creation, lectures and exercises (until 2023)\nCourse materials: https://julien-vitay.net/course-neurocomputing"
  },
  {
    "objectID": "teaching.html#deep-reinforcement-learning",
    "href": "teaching.html#deep-reinforcement-learning",
    "title": "Teaching",
    "section": "Deep Reinforcement Learning",
    "text": "Deep Reinforcement Learning\nLevel: Master\nResponsability: Creation, lectures and exercises\nCourse materials: https://julien-vitay.net/course-deeprl"
  },
  {
    "objectID": "teaching.html#computer-vision",
    "href": "teaching.html#computer-vision",
    "title": "Teaching",
    "section": "Computer Vision",
    "text": "Computer Vision\nLevel: Master\nResponsability: Creation, lectures and exercises (until 2019)"
  },
  {
    "objectID": "teaching.html#introduction-to-ai",
    "href": "teaching.html#introduction-to-ai",
    "title": "Teaching",
    "section": "Introduction to AI",
    "text": "Introduction to AI\nLevel: Bachelor\nResponsability: Exercises"
  },
  {
    "objectID": "impressum.html",
    "href": "impressum.html",
    "title": "Impressum",
    "section": "",
    "text": "Angaben gemäß § 5 TMG\n\n\nStraße der Nationen 62\n09107 Chemnitz\n\n\n\nTelefon: (+49) 371 531 39468\nE-Mail: julien.vitay@informatik.tu-chemnitz.de\nInternet: https://julien-vitay.net"
  },
  {
    "objectID": "impressum.html#julien-vitay",
    "href": "impressum.html#julien-vitay",
    "title": "Impressum",
    "section": "",
    "text": "Straße der Nationen 62\n09107 Chemnitz"
  },
  {
    "objectID": "impressum.html#kontakt",
    "href": "impressum.html#kontakt",
    "title": "Impressum",
    "section": "",
    "text": "Telefon: (+49) 371 531 39468\nE-Mail: julien.vitay@informatik.tu-chemnitz.de\nInternet: https://julien-vitay.net"
  },
  {
    "objectID": "research/hippocampus.html",
    "href": "research/hippocampus.html",
    "title": "Hippocampus",
    "section": "",
    "text": "The hippocampus is a key structure for episodic memory and spatial navigation. A fundamental step in hippocampus research was the discovery of place cells, which fire whenever an animal traverses a certain location known as the place field (O’Keefe and Nadel, 1978). At rest, place cells exhibit brief periods of fast oscillations termed sharp wave-ripples. During these events, place cell activity shows sequential patterns called forward replay and reverse replay: time-compressed, and sometimes time-reversed, reproductions of previously experienced sequences. Spatial experiences stored in the hippocampus can therefore be recalled at will during behavior.\nOur modeling work focuses on understanding how these replay patterns are learned and used for high-level cognitive processes such as decision-making and model-based reinforcement learning.\n\n\nRelated publications\nLorenz Gönner, Julien Vitay, and Fred H. Hamker (2017).\nPredictive Place-Cell Sequences for Goal-Finding Emerge from Goal Memory and the Cognitive Map: A Computational Model.\nFrontiers in Computational Neuroscience 11:84\ndoi:10.3389/fncom.2017.00084"
  },
  {
    "objectID": "research/geometricdeeplearning.html",
    "href": "research/geometricdeeplearning.html",
    "title": "Geometric deep learning",
    "section": "",
    "text": "The BMBF project ML@Karoprod (with the Fraunhofer IWU Dresden and Scale GmbH) aimed at investigating how to train deep neural networks on realistic finite element methods (FEM) simulations, for deep drawing and joining operations. By changing a set of process parameters such as “sheet thickness”, “drawing depth”, “hold-down force”, “draw gap”, and “insertion position”, our partners were able to create a dataset containing 879 deep drawing FEM simulations. The resulting meshes with over 20,000 nodes could be compared to a reference mesh to measure deviation.\n\nBy using implicit approaches as in NERF, we do not have to rely on just a few hundred simulated experiments in order to feed the neural network (which will most likely lead to overfitting), but thousands of measurements per experiment, representing thickness, thinning, plastic strain, etc., at individual locations. As opposed to using the non-Euclidean structure of the input space and performing expensive operations such as convolutions on the entire input mesh, this approach ensures efficient regularization of the NN by using individual positions as training patterns and proved to be very robust for modeling FEM simulations of different sizes and topologies.\n\nThe proposed model is capable of processing large meshes and predicting the deviation and thickness of the resulting mesh based on the input parameters. The results indicate that this method can be effectively combined with existing FEM methods. As a result, engineers will be able to refine FEM simulations faster and tune the most appropriate process parameters more easily. Furthermore, the model can be generalized to unseen data to a certain extent; for example, it could be used to generate simulation results for an unseen initial sheet thickness value.\n\nThe code is available at:\nhttps://github.com/hamkerlab/ML-Karoprod-MeshPredictor\n\n\nAida Farahani, Julien Vitay, and Fred H. Hamker (2022)\nDeep Neural Networks for Geometric Shape Deformation\nBergmann, R., Malburg, L., Rodermund, S.C., Timm, I.J. (eds) KI 2022: Advances in Artificial Intelligence. Lecture Notes in Computer Science, vol 13404. Springer, Cham.\ndoi:10.1007/978-3-031-15791-2_9"
  },
  {
    "objectID": "research/geometricdeeplearning.html#mlkaroprod-2018-2022",
    "href": "research/geometricdeeplearning.html#mlkaroprod-2018-2022",
    "title": "Geometric deep learning",
    "section": "",
    "text": "The BMBF project ML@Karoprod (with the Fraunhofer IWU Dresden and Scale GmbH) aimed at investigating how to train deep neural networks on realistic finite element methods (FEM) simulations, for deep drawing and joining operations. By changing a set of process parameters such as “sheet thickness”, “drawing depth”, “hold-down force”, “draw gap”, and “insertion position”, our partners were able to create a dataset containing 879 deep drawing FEM simulations. The resulting meshes with over 20,000 nodes could be compared to a reference mesh to measure deviation.\n\nBy using implicit approaches as in NERF, we do not have to rely on just a few hundred simulated experiments in order to feed the neural network (which will most likely lead to overfitting), but thousands of measurements per experiment, representing thickness, thinning, plastic strain, etc., at individual locations. As opposed to using the non-Euclidean structure of the input space and performing expensive operations such as convolutions on the entire input mesh, this approach ensures efficient regularization of the NN by using individual positions as training patterns and proved to be very robust for modeling FEM simulations of different sizes and topologies.\n\nThe proposed model is capable of processing large meshes and predicting the deviation and thickness of the resulting mesh based on the input parameters. The results indicate that this method can be effectively combined with existing FEM methods. As a result, engineers will be able to refine FEM simulations faster and tune the most appropriate process parameters more easily. Furthermore, the model can be generalized to unseen data to a certain extent; for example, it could be used to generate simulation results for an unseen initial sheet thickness value.\n\nThe code is available at:\nhttps://github.com/hamkerlab/ML-Karoprod-MeshPredictor\n\n\nAida Farahani, Julien Vitay, and Fred H. Hamker (2022)\nDeep Neural Networks for Geometric Shape Deformation\nBergmann, R., Malburg, L., Rodermund, S.C., Timm, I.J. (eds) KI 2022: Advances in Artificial Intelligence. Lecture Notes in Computer Science, vol 13404. Springer, Cham.\ndoi:10.1007/978-3-031-15791-2_9"
  },
  {
    "objectID": "research/deeplearning.html",
    "href": "research/deeplearning.html",
    "title": "Deep learning",
    "section": "",
    "text": "Deep learning"
  },
  {
    "objectID": "research/cybersecurity.html",
    "href": "research/cybersecurity.html",
    "title": "Cyber-security and anomaly detection",
    "section": "",
    "text": "The aim of the WAIKIKI (“Wissensbasierte Anomalieerkennung mittels Kuenstlicher Intelligenz in Kritischen Infrastrukturen”) project was to detect cyber-security-related anomalies in critical infrastructure. To realize this, we cooperated with researchers from the professorship of IT security (Prof. Dr. Andriy Panchenko) at the Brandenburgisch Technischen Universitaet Cottbus-Senftenberg and four partners from the industry.\nWe studied how different deep-learning methods can be used to monitor relevant computer systems. Due to the variety of data and information (e.g. sensor data in a tabular format, network traffic in byte format, or log data containing words and numbers), different methods from autoencoders to transformers must be considered and evaluated. Due to the fact that in computer systems a high amount of data can be created in a short amount of time, most datasets did not provide labels. As a consequence, mainly self-supervised and unsupervised methods are the focus of our research.\nThe detection is realized by the parallel monitoring and analyzing of network traffic and log data. For the latter, we use a compact convolutional transformer (CCT) (proposed by Hassani et al. (2021)) to detect anomalies in log data. It has been shown that transformers are able to encode the context in which a word appears. Due to this, we assume the analysis of log lines is a natural language task.\n\n\n\n\n\nThe CCT allows the process of multiple consecutive log lines at once and provides more contextual information to learn the correct system status. If a wrong log notice is detected, which does not fits in the actual context (for example a wrong process number or an error), this can be detected by the network.\n\n\nRené Larisch, Julien Vitay, and Fred H. Hamker (2023)\nDetecting Anomalies in System Logs With a Compact Convolutional Transformer\nIEEE Access 11, 113464-113479\ndoi:10.1109/ACCESS.2023.3323252"
  },
  {
    "objectID": "research/cybersecurity.html#waikiki-2019-2023",
    "href": "research/cybersecurity.html#waikiki-2019-2023",
    "title": "Cyber-security and anomaly detection",
    "section": "",
    "text": "The aim of the WAIKIKI (“Wissensbasierte Anomalieerkennung mittels Kuenstlicher Intelligenz in Kritischen Infrastrukturen”) project was to detect cyber-security-related anomalies in critical infrastructure. To realize this, we cooperated with researchers from the professorship of IT security (Prof. Dr. Andriy Panchenko) at the Brandenburgisch Technischen Universitaet Cottbus-Senftenberg and four partners from the industry.\nWe studied how different deep-learning methods can be used to monitor relevant computer systems. Due to the variety of data and information (e.g. sensor data in a tabular format, network traffic in byte format, or log data containing words and numbers), different methods from autoencoders to transformers must be considered and evaluated. Due to the fact that in computer systems a high amount of data can be created in a short amount of time, most datasets did not provide labels. As a consequence, mainly self-supervised and unsupervised methods are the focus of our research.\nThe detection is realized by the parallel monitoring and analyzing of network traffic and log data. For the latter, we use a compact convolutional transformer (CCT) (proposed by Hassani et al. (2021)) to detect anomalies in log data. It has been shown that transformers are able to encode the context in which a word appears. Due to this, we assume the analysis of log lines is a natural language task.\n\n\n\n\n\nThe CCT allows the process of multiple consecutive log lines at once and provides more contextual information to learn the correct system status. If a wrong log notice is detected, which does not fits in the actual context (for example a wrong process number or an error), this can be detected by the network.\n\n\nRené Larisch, Julien Vitay, and Fred H. Hamker (2023)\nDetecting Anomalies in System Logs With a Compact Convolutional Transformer\nIEEE Access 11, 113464-113479\ndoi:10.1109/ACCESS.2023.3323252"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "AllJournalsConference proceedingsBook chaptersTheses\n\n\n2023\nRené Larisch, Julien Vitay, and Fred H. Hamker (2023)  Detecting Anomalies in System Logs With a Compact Convolutional Transformer  IEEE Access 11, 113464-113479  doi:10.1109/ACCESS.2023.3323252 \n  URL   PDF\n\nJavier Baladron, Julien Vitay, Torsten Fietzek, and Fred H. Hamker (2023)  The contribution of the basal ganglia and cerebellum to motor learning: A neuro-computational approach  PLoS Comput Biol 19(4): e1011024  doi:10.1371/journal.pcbi.1011024 \n  URL   PDF   Code\n\n2022\nCarolin Scholl, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022)  Enhanced Habit Formation in Tourette Patients Explained by Shortcut Modulation in a Hierarchical Cortico-Basal Ganglia Model  Brain Structure and Function 227, 1031-1050  doi:10.1007/s00429-021-02446-x \n  URL   PDF   Preprint\n\nOliver Maith, Helge Ülo Dinkelbach, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022)  BOLD monitoring in the neural simulator ANNarchy  Frontiers in Neuroinformatics 16:790966  doi:10.3389/fninf.2022.790966 \n  URL   PDF   Code\n\nHelge Ülo Dinkelbach, Badr-Eddine Bouhlal, Julien Vitay, and Fred H. Hamker (2022)  Auto-selection of an optimal sparse matrix format in the neuro-simulator ANNarchy  Frontiers in Neuroinformatics 16:877945  doi:10.3389/fninf.2022.877945 \n  URL   PDF   Code\n\nAida Farahani, Julien Vitay, and Fred H. Hamker (2022)  Deep Neural Networks for Geometric Shape Deformation  In: Bergmann, R., Malburg, L., Rodermund, S.C., Timm, I.J. (eds). KI 2022: Advances in Artificial Intelligence. Lecture Notes in Computer Science, vol 13404. Springer, Cham  doi:10.1007/978-3-031-15791-2_9 \n  URL   PDF\n\nNicolas Kuske, Marco Ragni, Florian Röhrbein, Julien Vitay, and Fred H. Hamker (2022)  Demands and potentials of different levels of neuro-cognitive models für human spatial cognition  In: E. Ferstl, L. Konieczny, & R. Stülpnagel (eds). Proceedings of KogWiss2022, the 15th Biannual Conference of the German Society for Cognitive Science (pp. 115-116)  doi:10.6094/UNIFR/229611 \n  URL   PDF\n\n2021\nChaithanya Kumar Mummadi, Ranjitha Subramaniam, Robin Hutmacher, Julien Vitay, Volker Fischer, and Jan Hendrik Metzen (2021)  Does enhanced shape bias improve neural network robustness to common corruptions?  In: International Conference on Learning Representations (ICLR) \n  URL   PDF\n\nAida Farahani, Julien Vitay, and Fred H. Hamker (2021)  Geometric Deep Learning and solutions for the industry  Workshop 3D-NordOst 2021. Tagungsband 23. Anwendungsbezogener Workshop zur Erfassung, Modellierung, Verarbeitung und Auswertung von 3D-Daten, Berlin, 02./03.12.2021: 105-113. ISBN: 978-3-942709-27-9 \n\nPayam Atoofi, Julien Vitay, and Fred H. Hamker (2021)  Geometric Deep Learning: Graph Neural Networks, Challenges, and Breakthroughs  Workshop 3D-NordOst 2021. Tagungsband 23. Anwendungsbezogener Workshop zur Erfassung, Modellierung, Verarbeitung und Auswertung von 3D-Daten, Berlin, 02./03.12.2021:115-124. ISBN: 978-3-942709-27-9 \n\n2020\nEnrico Schröder, Mirko Mählisch, Julien Vitay, and Fred H. Hamker (2020)  Monocular 3D Object Detection Using Feature Map Transformation: Towards Learning Perspective-Invariant Scene Representations  In: 2020 Fourth IEEE International Conference on Robotic Computing (IRC)  doi:10.1109/IRC.2020.00066 \n  URL\n\nEnrico Schröder, Sascha Braun, Mirko Mählisch, Julien Vitay, and Fred H. Hamker (2020)  Feature Map Transformation for Multi-sensor Fusion in Object Detection Networks for Autonomous Driving  In: Arai, K., Kapoor, S. (eds). Advances in Computer Vision. CVC 2019. Advances in Intelligent Systems and Computing, vol 944. Springer, Cham  doi:10.1007/978-3-030-17798-0_12 \n  URL   PDF\n\n2019\nKatharina Schmid, Julien Vitay, and Fred H. Hamker (2019)  Forward Models in the Cerebellum using Reservoirs and Perturbation Learning  In: 2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany  doi:10.32470/CCN.2019.1139-0 \n  URL   PDF   Poster\n\nHelge Ülo Dinkelbach, Julien Vitay, and Fred H. Hamker (2019)  Scalable simulation of rate-coded and spiking neural networks on shared memory systems  In: 2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany  doi:10.32470/CCN.2019.1109-0 \n  URL   PDF   Poster\n\nValentin Forch, Julien Vitay, and Fred H. Hamker (2019)  Recurrent Spatial Attention for Facial Emotion Recognition  In Proceedings of Workshop Localize IT, Chemnitz Linux-Tage, Chemnitz (Germany). \n  PDF\n\n2018\nFrancesc Villagrasa, Javier Baladron, Julien Vitay, Henning Schroll, Evan G. Antzoulatos, Earl K. Miller, and Fred H. Hamker (2018)  On the role of cortex-basal ganglia interactions for category learning: A neuro-computational approach  Journal of Neuroscience 38(44) 9551-9562  doi:10.1523/JNEUROSCI.0874-18.2018 \n  URL   PDF\n\nEnrico Schröder, Mirko Mählisch, Julien Vitay, and Fred H. Hamker (2018)  Fusion of Camera and Lidar Data for Object Detection using Neural Networks  In Proceedings of 12. Workshop Fahrerassistenzsysteme und automatisiertes Fahren FAS 2018, 26-28.09.2018, Walting im Altmühltal (Germany). 138-146. Darmstadt:Uni-DAS e.V. \n  PDF\n\n2017\nJulien Vitay (2017)  On the role of dopamine in motivated behavior: a neuro-computational approach.  Habilitation (Technische Universität Chemnitz). \n  URL   PDF\n\nLorenz Gönner, Julien Vitay, and Fred H. Hamker (2017)  Predictive Place-Cell Sequences for Goal-Finding Emerge from Goal Memory and the Cognitive Map: A Computational Model  Frontiers in Computational Neuroscience 11:84  doi:10.3389/fncom.2017.00084 \n  URL   PDF\n\nNicolas P. Rougier, Konrad Hinsen, Frédéric Alexandre, Thomas Arildsen, Lorena A. Barba, Fabien C.Y. Benureau, C. Titus Brown, Pierre de Buyl, Ozan Caglayan, Andrew P. Davison, Marc-André Delsuc, Georgios Detorakis, Alexandra K. Diem, Damien Drix, Pierre Enel, Benoît Girard, Olivia Guest, Matt G. Hall, Rafael N. Henriques, Xavier Hinaut, Kamil S. Jaron, Mehdi Khamassi, Almar Klein, Tiina Manninen, Pietro Marchesi, Daniel McGlinn, Christoph Metzner, Owen Petchey, Hans Ekkehard Plesser, Timothée Poisot, Karthik Ram, Yoav Ram, Etienne Roesch, Cyrille Rossant, Vahid Rostami, Aaron Shifman, Joseph Stachelek, Marcel Stimberg, Frank Stollmeier, Federico Vaggi, Guillaume Viejo, Julien Vitay, Anya E. Vostinar, Roman Yurchak, and Tiziano Zito (2017)  Sustainable computational science: the ReScience initiative  PeerJ Computer Science 3:e142  doi:10.7717/peerj-cs.142 \n  URL   PDF\n\nWinfried Lötzsch, Julien Vitay, and Fred H. Hamker (2017)  Training a deep policy gradient-based neural network with asynchronous learners on a simulated robotic problem  In: Eibl, M. and Gaedke, M. (eds). INFORMATIK 2017. Gesellschaft für Informatik, Bonn. 2143-2154  doi:10.18420/in2017_214 \n  URL   PDF\n\n2016\nJulien Vitay (2016)  [Re] Robust timing and motor patterns by taming chaos in recurrent neural networks  Rescience, 2(1)  doi:10.5281/zenodo.159545 \n  URL   PDF   Code\n\n2015\nJulien Vitay, Helge Ülo Dinkelbach, and Fred H. Hamker (2015)  ANNarchy: a code generation approach to neural simulations on parallel hardware  Frontiers in Neuroinformatics 9:19  doi:10.3389/fninf.2015.00019 \n  URL   PDF   Code\n\n2014\nJulien Vitay and Fred H. Hamker (2014)  Timing and expectation of reward: a neuro-computational model of the afferents to the ventral tegmental area  Frontiers in Neurorobotics 8:4  doi:10.3389/fnbot.2014.00004 \n  URL   PDF   Code\n\nHenning Schroll, Julien Vitay, and Fred H. Hamker (2014)  Dysfunctional and compensatory synaptic plasticity in Parkinson’s disease  European Journal of Neuroscience, 39: 688-702  doi:10.1111/ejn.12434 \n  URL   PDF\n\n2012\nHelge Ü. Dinkelbach, Julien Vitay, and Fred H. Hamker (2012)  Comparison of GPU- and CPU-implementations of mean-firing rate neural networks on parallel hardware  Network: Computation in Neural Systems 23(4)  doi:10.3109/0954898X.2012.739292 \n  URL   PDF\n\nHenning Schroll, Julien Vitay, and Fred H. Hamker (2012)  Working memory and response selection: A computational account of interactions among cortico-basalganglio-thalamic loops  Neural Networks, 26  doi:10.1016/j.neunet.2011.10.008 \n  URL   PDF\n\nJulien Vitay and Fred H. Hamker (2012)  Basal Ganglia learning  In Encyclopedia of the Sciences of Learning. Seel, Norbert M. (ed).  doi:10.1007/978-1-4419-1428-6 \n  URL\n\n2011\nJulien Vitay and Fred H. Hamker (2011)  A Neuroscientific View on the Role of Emotions in Behaving Cognitive Agents  Künstliche Intelligenz 25(3)  doi:10.1007/s13218-011-0106-y \n  PDF\n\n2010\nJulien Vitay and Fred H. Hamker (2010)  A computational model of basal ganglia and its role in memory retrieval in rewarded visual memory tasks  Frontiers in Computational Neuroscience 4(13)  doi:10.3389/fncom.2010.00013 \n  URL   PDF\n\n2009\nJulien Vitay, Jérémy Fix, Frederik Beuth, Henning Schroll, and Fred H. Hamker (2009)  Biological Models of Reinforcement Learning  Künstliche Intelligenz 23(3) \n  PDF\n\n2008\nJulien Vitay and Fred H. Hamker (2008)  Sustained Activities and Retrieval in a Computational Model of the Perirhinal Cortex  Journal of Cognitive Neuroscience 20(11)  doi:10.1162/jocn.2008.20147 \n  URL   PDF\n\n2007\nJulien Vitay and Fred H. Hamker (2007)  On the role of dopamine in cognitive vision  In: Paletta, L., Rome, E. (eds). Attention in Cognitive Systems. Theories and Systems from an Interdisciplinary Viewpoint. WAPCV 2007. Lecture Notes in Computer Science(), vol 4840. Springer, Berlin, Heidelberg  doi:10.1007/978-3-540-77343-6_23 \n  URL   PDF\n\n2006\nJulien Vitay (2006)  Emergence of sensorimotor functions on a numerical distributed neural substrate  PhD thesis (Université Henri-Poincaré Nancy-I) \n  PDF\n\nJérémy Fix, Julien Vitay, and Nicolas P. Rougier (2006)  A Distributed Computational Model of Spatial Memory Anticipation During a Visual Search Task  In: Butz, M.V., Sigaud, O., Pezzulo, G., Baldassarre, G. (eds). Anticipatory Behavior in Adaptive Learning Systems. ABiALS 2006. Lecture Notes in Computer Science(), vol 4520. Springer, Berlin, Heidelberg  doi:10.1007/978-3-540-74262-3_10 \n  URL   PDF\n\n2005\nNicolas P. Rougier and Julien Vitay (2005)  Emergence of attention within a neural population  Neural Networks 19(5)  doi:10.1016/j.neunet.2005.04.004 \n  URL   PDF\n\nJulien Vitay, Nicolas P. Rougier, and Frédéric Alexandre (2005)  A distributed model of spatial visual attention  In: Wermter, S., Palm, G., Elshaw, M. (eds). Biomimetic Neural Learning for Intelligent Robots. Lecture Notes in Computer Science(), vol 3575. Springer, Berlin, Heidelberg  doi:10.1007/11521082_4 \n  URL   PDF\n\nJulien Vitay (2005)  Towards Teaching a Robot to Count  In: Berthouze, L., Kaplan, F., Kozima, H., Yano, H., Konczak, J., Metta, G., Nadel, J., Sandini, G., Stojanov, G. and Balkenius, C. (eds). Proceedings of the Fifth International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. Lund University Cognitive Studies, 123. ISBN 91-974741-4-2 \n  PDF\n\n\n\n2023\nRené Larisch, Julien Vitay, and Fred H. Hamker (2023)  Detecting Anomalies in System Logs With a Compact Convolutional Transformer  IEEE Access 11, 113464-113479  doi:10.1109/ACCESS.2023.3323252 \n  URL   PDF\n\nJavier Baladron, Julien Vitay, Torsten Fietzek, and Fred H. Hamker (2023)  The contribution of the basal ganglia and cerebellum to motor learning: A neuro-computational approach  PLoS Comput Biol 19(4): e1011024  doi:10.1371/journal.pcbi.1011024 \n  URL   PDF   Code\n\n2022\nCarolin Scholl, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022)  Enhanced Habit Formation in Tourette Patients Explained by Shortcut Modulation in a Hierarchical Cortico-Basal Ganglia Model  Brain Structure and Function 227, 1031-1050  doi:10.1007/s00429-021-02446-x \n  URL   PDF   Preprint\n\nOliver Maith, Helge Ülo Dinkelbach, Javier Baladron, Julien Vitay, and Fred H. Hamker (2022)  BOLD monitoring in the neural simulator ANNarchy  Frontiers in Neuroinformatics 16:790966  doi:10.3389/fninf.2022.790966 \n  URL   PDF   Code\n\nHelge Ülo Dinkelbach, Badr-Eddine Bouhlal, Julien Vitay, and Fred H. Hamker (2022)  Auto-selection of an optimal sparse matrix format in the neuro-simulator ANNarchy  Frontiers in Neuroinformatics 16:877945  doi:10.3389/fninf.2022.877945 \n  URL   PDF   Code\n\n2018\nFrancesc Villagrasa, Javier Baladron, Julien Vitay, Henning Schroll, Evan G. Antzoulatos, Earl K. Miller, and Fred H. Hamker (2018)  On the role of cortex-basal ganglia interactions for category learning: A neuro-computational approach  Journal of Neuroscience 38(44) 9551-9562  doi:10.1523/JNEUROSCI.0874-18.2018 \n  URL   PDF\n\n2017\nLorenz Gönner, Julien Vitay, and Fred H. Hamker (2017)  Predictive Place-Cell Sequences for Goal-Finding Emerge from Goal Memory and the Cognitive Map: A Computational Model  Frontiers in Computational Neuroscience 11:84  doi:10.3389/fncom.2017.00084 \n  URL   PDF\n\nNicolas P. Rougier, Konrad Hinsen, Frédéric Alexandre, Thomas Arildsen, Lorena A. Barba, Fabien C.Y. Benureau, C. Titus Brown, Pierre de Buyl, Ozan Caglayan, Andrew P. Davison, Marc-André Delsuc, Georgios Detorakis, Alexandra K. Diem, Damien Drix, Pierre Enel, Benoît Girard, Olivia Guest, Matt G. Hall, Rafael N. Henriques, Xavier Hinaut, Kamil S. Jaron, Mehdi Khamassi, Almar Klein, Tiina Manninen, Pietro Marchesi, Daniel McGlinn, Christoph Metzner, Owen Petchey, Hans Ekkehard Plesser, Timothée Poisot, Karthik Ram, Yoav Ram, Etienne Roesch, Cyrille Rossant, Vahid Rostami, Aaron Shifman, Joseph Stachelek, Marcel Stimberg, Frank Stollmeier, Federico Vaggi, Guillaume Viejo, Julien Vitay, Anya E. Vostinar, Roman Yurchak, and Tiziano Zito (2017)  Sustainable computational science: the ReScience initiative  PeerJ Computer Science 3:e142  doi:10.7717/peerj-cs.142 \n  URL   PDF\n\n2016\nJulien Vitay (2016)  [Re] Robust timing and motor patterns by taming chaos in recurrent neural networks  Rescience, 2(1)  doi:10.5281/zenodo.159545 \n  URL   PDF   Code\n\n2015\nJulien Vitay, Helge Ülo Dinkelbach, and Fred H. Hamker (2015)  ANNarchy: a code generation approach to neural simulations on parallel hardware  Frontiers in Neuroinformatics 9:19  doi:10.3389/fninf.2015.00019 \n  URL   PDF   Code\n\n2014\nJulien Vitay and Fred H. Hamker (2014)  Timing and expectation of reward: a neuro-computational model of the afferents to the ventral tegmental area  Frontiers in Neurorobotics 8:4  doi:10.3389/fnbot.2014.00004 \n  URL   PDF   Code\n\nHenning Schroll, Julien Vitay, and Fred H. Hamker (2014)  Dysfunctional and compensatory synaptic plasticity in Parkinson’s disease  European Journal of Neuroscience, 39: 688-702  doi:10.1111/ejn.12434 \n  URL   PDF\n\n2012\nHelge Ü. Dinkelbach, Julien Vitay, and Fred H. Hamker (2012)  Comparison of GPU- and CPU-implementations of mean-firing rate neural networks on parallel hardware  Network: Computation in Neural Systems 23(4)  doi:10.3109/0954898X.2012.739292 \n  URL   PDF\n\nHenning Schroll, Julien Vitay, and Fred H. Hamker (2012)  Working memory and response selection: A computational account of interactions among cortico-basalganglio-thalamic loops  Neural Networks, 26  doi:10.1016/j.neunet.2011.10.008 \n  URL   PDF\n\n2011\nJulien Vitay and Fred H. Hamker (2011)  A Neuroscientific View on the Role of Emotions in Behaving Cognitive Agents  Künstliche Intelligenz 25(3)  doi:10.1007/s13218-011-0106-y \n  PDF\n\n2010\nJulien Vitay and Fred H. Hamker (2010)  A computational model of basal ganglia and its role in memory retrieval in rewarded visual memory tasks  Frontiers in Computational Neuroscience 4(13)  doi:10.3389/fncom.2010.00013 \n  URL   PDF\n\n2009\nJulien Vitay, Jérémy Fix, Frederik Beuth, Henning Schroll, and Fred H. Hamker (2009)  Biological Models of Reinforcement Learning  Künstliche Intelligenz 23(3) \n  PDF\n\n2008\nJulien Vitay and Fred H. Hamker (2008)  Sustained Activities and Retrieval in a Computational Model of the Perirhinal Cortex  Journal of Cognitive Neuroscience 20(11)  doi:10.1162/jocn.2008.20147 \n  URL   PDF\n\n2005\nNicolas P. Rougier and Julien Vitay (2005)  Emergence of attention within a neural population  Neural Networks 19(5)  doi:10.1016/j.neunet.2005.04.004 \n  URL   PDF\n\n\n\n2022\nAida Farahani, Julien Vitay, and Fred H. Hamker (2022)  Deep Neural Networks for Geometric Shape Deformation  In: Bergmann, R., Malburg, L., Rodermund, S.C., Timm, I.J. (eds). KI 2022: Advances in Artificial Intelligence. Lecture Notes in Computer Science, vol 13404. Springer, Cham  doi:10.1007/978-3-031-15791-2_9 \n  URL   PDF\n\nNicolas Kuske, Marco Ragni, Florian Röhrbein, Julien Vitay, and Fred H. Hamker (2022)  Demands and potentials of different levels of neuro-cognitive models für human spatial cognition  In: E. Ferstl, L. Konieczny, & R. Stülpnagel (eds). Proceedings of KogWiss2022, the 15th Biannual Conference of the German Society for Cognitive Science (pp. 115-116)  doi:10.6094/UNIFR/229611 \n  URL   PDF\n\n2021\nChaithanya Kumar Mummadi, Ranjitha Subramaniam, Robin Hutmacher, Julien Vitay, Volker Fischer, and Jan Hendrik Metzen (2021)  Does enhanced shape bias improve neural network robustness to common corruptions?  In: International Conference on Learning Representations (ICLR) \n  URL   PDF\n\nAida Farahani, Julien Vitay, and Fred H. Hamker (2021)  Geometric Deep Learning and solutions for the industry  Workshop 3D-NordOst 2021. Tagungsband 23. Anwendungsbezogener Workshop zur Erfassung, Modellierung, Verarbeitung und Auswertung von 3D-Daten, Berlin, 02./03.12.2021: 105-113. ISBN: 978-3-942709-27-9 \n\nPayam Atoofi, Julien Vitay, and Fred H. Hamker (2021)  Geometric Deep Learning: Graph Neural Networks, Challenges, and Breakthroughs  Workshop 3D-NordOst 2021. Tagungsband 23. Anwendungsbezogener Workshop zur Erfassung, Modellierung, Verarbeitung und Auswertung von 3D-Daten, Berlin, 02./03.12.2021:115-124. ISBN: 978-3-942709-27-9 \n\n2020\nEnrico Schröder, Mirko Mählisch, Julien Vitay, and Fred H. Hamker (2020)  Monocular 3D Object Detection Using Feature Map Transformation: Towards Learning Perspective-Invariant Scene Representations  In: 2020 Fourth IEEE International Conference on Robotic Computing (IRC)  doi:10.1109/IRC.2020.00066 \n  URL\n\nEnrico Schröder, Sascha Braun, Mirko Mählisch, Julien Vitay, and Fred H. Hamker (2020)  Feature Map Transformation for Multi-sensor Fusion in Object Detection Networks for Autonomous Driving  In: Arai, K., Kapoor, S. (eds). Advances in Computer Vision. CVC 2019. Advances in Intelligent Systems and Computing, vol 944. Springer, Cham  doi:10.1007/978-3-030-17798-0_12 \n  URL   PDF\n\n2019\nKatharina Schmid, Julien Vitay, and Fred H. Hamker (2019)  Forward Models in the Cerebellum using Reservoirs and Perturbation Learning  In: 2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany  doi:10.32470/CCN.2019.1139-0 \n  URL   PDF   Poster\n\nHelge Ülo Dinkelbach, Julien Vitay, and Fred H. Hamker (2019)  Scalable simulation of rate-coded and spiking neural networks on shared memory systems  In: 2019 Conference on Cognitive Computational Neuroscience, 13-16 September 2019, Berlin, Germany  doi:10.32470/CCN.2019.1109-0 \n  URL   PDF   Poster\n\nValentin Forch, Julien Vitay, and Fred H. Hamker (2019)  Recurrent Spatial Attention for Facial Emotion Recognition  In Proceedings of Workshop Localize IT, Chemnitz Linux-Tage, Chemnitz (Germany). \n  PDF\n\n2018\nEnrico Schröder, Mirko Mählisch, Julien Vitay, and Fred H. Hamker (2018)  Fusion of Camera and Lidar Data for Object Detection using Neural Networks  In Proceedings of 12. Workshop Fahrerassistenzsysteme und automatisiertes Fahren FAS 2018, 26-28.09.2018, Walting im Altmühltal (Germany). 138-146. Darmstadt:Uni-DAS e.V. \n  PDF\n\n2017\nWinfried Lötzsch, Julien Vitay, and Fred H. Hamker (2017)  Training a deep policy gradient-based neural network with asynchronous learners on a simulated robotic problem  In: Eibl, M. and Gaedke, M. (eds). INFORMATIK 2017. Gesellschaft für Informatik, Bonn. 2143-2154  doi:10.18420/in2017_214 \n  URL   PDF\n\n2006\nJérémy Fix, Julien Vitay, and Nicolas P. Rougier (2006)  A Distributed Computational Model of Spatial Memory Anticipation During a Visual Search Task  In: Butz, M.V., Sigaud, O., Pezzulo, G., Baldassarre, G. (eds). Anticipatory Behavior in Adaptive Learning Systems. ABiALS 2006. Lecture Notes in Computer Science(), vol 4520. Springer, Berlin, Heidelberg  doi:10.1007/978-3-540-74262-3_10 \n  URL   PDF\n\n2005\nJulien Vitay (2005)  Towards Teaching a Robot to Count  In: Berthouze, L., Kaplan, F., Kozima, H., Yano, H., Konczak, J., Metta, G., Nadel, J., Sandini, G., Stojanov, G. and Balkenius, C. (eds). Proceedings of the Fifth International Workshop on Epigenetic Robotics: Modeling Cognitive Development in Robotic Systems. Lund University Cognitive Studies, 123. ISBN 91-974741-4-2 \n  PDF\n\n\n\n2012\nJulien Vitay and Fred H. Hamker (2012)  Basal Ganglia learning  In Encyclopedia of the Sciences of Learning. Seel, Norbert M. (ed).  doi:10.1007/978-1-4419-1428-6 \n  URL\n\n2007\nJulien Vitay and Fred H. Hamker (2007)  On the role of dopamine in cognitive vision  In: Paletta, L., Rome, E. (eds). Attention in Cognitive Systems. Theories and Systems from an Interdisciplinary Viewpoint. WAPCV 2007. Lecture Notes in Computer Science(), vol 4840. Springer, Berlin, Heidelberg  doi:10.1007/978-3-540-77343-6_23 \n  URL   PDF\n\n2005\nJulien Vitay, Nicolas P. Rougier, and Frédéric Alexandre (2005)  A distributed model of spatial visual attention  In: Wermter, S., Palm, G., Elshaw, M. (eds). Biomimetic Neural Learning for Intelligent Robots. Lecture Notes in Computer Science(), vol 3575. Springer, Berlin, Heidelberg  doi:10.1007/11521082_4 \n  URL   PDF\n\n\n\n2017\nJulien Vitay (2017)  On the role of dopamine in motivated behavior: a neuro-computational approach.  Habilitation (Technische Universität Chemnitz). \n  URL   PDF\n\n2006\nJulien Vitay (2006)  Emergence of sensorimotor functions on a numerical distributed neural substrate  PhD thesis (Université Henri-Poincaré Nancy-I) \n  PDF"
  },
  {
    "objectID": "post/successor_representations/index.html",
    "href": "post/successor_representations/index.html",
    "title": "Successor Representations",
    "section": "",
    "text": "There are two main families of reinforcement learning (RL, Sutton and Barto, 2017) algorithms:\n\nModel-free (MF) methods estimate the value of a state V^\\pi(s) or of a state-action pair Q^\\pi(s, a) by sampling trajectories and averaging the obtained returns (Monte-Carlo control), or by estimating the Bellman equations (Temporal difference - TD):\n\nV^\\pi(s) = \\mathbb{E}_{\\pi} [\\sum_{k=0} \\gamma^k \\, r_{t+k+1}  | s_t = s] = \\mathbb{E}_{\\pi} [r_{t+1} + \\gamma \\, V^\\pi(s_{t+1})  | s_t = s]\nQ^\\pi(s, a) = \\mathbb{E}_{\\pi} [\\sum_{k=0} \\gamma^k \\, r_{t+k+1}  | s_t = s, a_t = a] = \\mathbb{E}_{\\pi} [r_{t+1} + \\gamma \\, Q^\\pi(s_{t+1}, a_{t+1})  | s_t = s, a_t = a]\n\nModel-based (MB) methods use (or learn) a model of the environment - transition probabilities p(s_{t+1} | s_t, a_t) and reward probabilities r(s_t, a_t, s_{t+1}) - and use it to plan trajectories maximizing the theoretical return, either through some form of forward planning (search tree) or using dynamic programming (solving the Bellman equations directly).\n\n\\pi^* = \\text{argmax}_{\\pi} \\; p(s_0) \\, \\sum_{t=0}^\\infty \\gamma^t \\, p(s_{t+1} | s_t, a_t) \\, \\pi(s_t, a_t) \\, r(s_t, a_t, s_{t+1})\nV^*(s) = \\max_a \\sum_{s'} p(s' | s, a) \\, (r(s_t, a, s')+ \\gamma \\, V^*(s'))\nThe main advantage of model-free methods is their speed: they cache the future of the system into value functions. When having to take a decision at time t, we only need to look at the action with the highest Q-value in the state s_t and take it. If the Q-values are optimal, this is the optimal policy. Oppositely, model-based algorithms have to plan sequentially in the state-action space, which can be very long if the problem has a long temporal horizon.\nThe main drawback of MF methods is their inflexibility when the reward distribution changes. When the reward associated with a transition changes (the source of reward has vanished, its nature has changed, the rules of the game have changed, etc), each action leading to that transition has to be experienced multiple times before the corresponding values reflect that change. This is due to the use of the temporal difference (TD) algorithm, where the reward prediction error (RPE) is used to update values:\n\\delta_t = r_{t+1} + \\gamma \\, V^\\pi(s_{t+1}) - V^\\pi(s_t)\n\\Delta V^\\pi(s_t) = \\alpha \\, \\delta_t\nWhen the reward associated to a transition changes drastically, only the last state (or action) is updated after that experience (unless we use eligibility traces). Only multiple repetitions of the same trajectory would allow changing the initial decisions. This is opposite to MB methods, where a change in the reward distribution would very quickly influence the planning of the optimal trajectory. In MB, the reward probabilities can be estimated with:\n\n    \\Delta r(s_t, a_t, s_{t+1}) = \\alpha \\, (r_{t+1} - r(s_t, a_t, s_{t+1}))\n\nwith r_{t+1} being the reward obtained during one sampled transition. The transition probabilities can also be learned from experience using:\n\n    \\Delta p(s' | s_t, a_t) = \\alpha \\, (\\mathbb{I}(s_{t+1} = s') - p(s' | s_t, a_t))\n\nwhere \\mathbb{I}(b) is 1 when b is true, 0 otherwise. Depending on the learning rate, changes in the environment dynamics can be very quickly learned by MB methods, as updates do not depend on other estimates (there is no bootstrapping contrary to TD).\n\n\n\nThe model-free RPE has become a very influential model of dopaminergic (DA) activation in the ventral tegmental area (VTA) and substantia nigra pars compacta (SNc). At the beginning of classical Pavlovian conditioning, DA cells react phasically to unconditioned stimuli (US, rewards). After enough conditioning trials, DA cells only react to conditioned stimuli (CS), i.e. stimuli which predict the delivery of a reward. Moreover, if the reward is omitted, DA cells exhibit a pause in firing. This pattern of activation corresponds to the RPE: DA cells respond to unexpected reward events, either positively when more reward than expected is received, or negatively when less reward is delivered. The simplicity of this model has made RPE a successful model of DA activity (but see Vitay and Hamker (2014) for a more detailed model).\nA similar but not identical functional dichotomy as MF/MB opposes deliberative goal-directed behavior and inflexible stimulus-response associations called habits (Dickinson and Balleine, 2002). Goal-directed behavior is sensitive to reward devaluation: if an outcome was previously rewarding but ceases to be (for example, a poisonous product is injected into some food reward, even outside the conditioning phase), goal-directed behavior would quickly learn to avoid that outcome, while habitual behavior will continue to seek for it. Over-training can transform goal-directed behavior into habits (Corbit and Balleine, 2011). Habits are usually considered as a model-free learning behavior, while goal-directed behavior implies the use of a world model. The dual system theory discusses the arbitration mechanisms necessary to coordinate these two learning frameworks (Lee et al., 2014).\nBoth forms of behavior are thought to happen concurrently in the brain, with model-based / goal-directed behavior classically assigned to the prefrontal cortex and the hippocampus and model-free / habitual behavior mapped to the ventral basal ganglia and the dopaminergic system. However, recent results and theories suggest that these two functional systems are largely overlapping and that even dopamine firing might reflect model-based processes (Doll et al., 2012; Miller et al., 2018). It is yet to be understood how these two extreme mechanisms of the RL spectrum might coexist in the brain and be coordinated: successor representations might provide us with additional useful insights into the functioning of the brain."
  },
  {
    "objectID": "post/successor_representations/index.html#motivation",
    "href": "post/successor_representations/index.html#motivation",
    "title": "Successor Representations",
    "section": "",
    "text": "There are two main families of reinforcement learning (RL, Sutton and Barto, 2017) algorithms:\n\nModel-free (MF) methods estimate the value of a state V^\\pi(s) or of a state-action pair Q^\\pi(s, a) by sampling trajectories and averaging the obtained returns (Monte-Carlo control), or by estimating the Bellman equations (Temporal difference - TD):\n\nV^\\pi(s) = \\mathbb{E}_{\\pi} [\\sum_{k=0} \\gamma^k \\, r_{t+k+1}  | s_t = s] = \\mathbb{E}_{\\pi} [r_{t+1} + \\gamma \\, V^\\pi(s_{t+1})  | s_t = s]\nQ^\\pi(s, a) = \\mathbb{E}_{\\pi} [\\sum_{k=0} \\gamma^k \\, r_{t+k+1}  | s_t = s, a_t = a] = \\mathbb{E}_{\\pi} [r_{t+1} + \\gamma \\, Q^\\pi(s_{t+1}, a_{t+1})  | s_t = s, a_t = a]\n\nModel-based (MB) methods use (or learn) a model of the environment - transition probabilities p(s_{t+1} | s_t, a_t) and reward probabilities r(s_t, a_t, s_{t+1}) - and use it to plan trajectories maximizing the theoretical return, either through some form of forward planning (search tree) or using dynamic programming (solving the Bellman equations directly).\n\n\\pi^* = \\text{argmax}_{\\pi} \\; p(s_0) \\, \\sum_{t=0}^\\infty \\gamma^t \\, p(s_{t+1} | s_t, a_t) \\, \\pi(s_t, a_t) \\, r(s_t, a_t, s_{t+1})\nV^*(s) = \\max_a \\sum_{s'} p(s' | s, a) \\, (r(s_t, a, s')+ \\gamma \\, V^*(s'))\nThe main advantage of model-free methods is their speed: they cache the future of the system into value functions. When having to take a decision at time t, we only need to look at the action with the highest Q-value in the state s_t and take it. If the Q-values are optimal, this is the optimal policy. Oppositely, model-based algorithms have to plan sequentially in the state-action space, which can be very long if the problem has a long temporal horizon.\nThe main drawback of MF methods is their inflexibility when the reward distribution changes. When the reward associated with a transition changes (the source of reward has vanished, its nature has changed, the rules of the game have changed, etc), each action leading to that transition has to be experienced multiple times before the corresponding values reflect that change. This is due to the use of the temporal difference (TD) algorithm, where the reward prediction error (RPE) is used to update values:\n\\delta_t = r_{t+1} + \\gamma \\, V^\\pi(s_{t+1}) - V^\\pi(s_t)\n\\Delta V^\\pi(s_t) = \\alpha \\, \\delta_t\nWhen the reward associated to a transition changes drastically, only the last state (or action) is updated after that experience (unless we use eligibility traces). Only multiple repetitions of the same trajectory would allow changing the initial decisions. This is opposite to MB methods, where a change in the reward distribution would very quickly influence the planning of the optimal trajectory. In MB, the reward probabilities can be estimated with:\n\n    \\Delta r(s_t, a_t, s_{t+1}) = \\alpha \\, (r_{t+1} - r(s_t, a_t, s_{t+1}))\n\nwith r_{t+1} being the reward obtained during one sampled transition. The transition probabilities can also be learned from experience using:\n\n    \\Delta p(s' | s_t, a_t) = \\alpha \\, (\\mathbb{I}(s_{t+1} = s') - p(s' | s_t, a_t))\n\nwhere \\mathbb{I}(b) is 1 when b is true, 0 otherwise. Depending on the learning rate, changes in the environment dynamics can be very quickly learned by MB methods, as updates do not depend on other estimates (there is no bootstrapping contrary to TD).\n\n\n\nThe model-free RPE has become a very influential model of dopaminergic (DA) activation in the ventral tegmental area (VTA) and substantia nigra pars compacta (SNc). At the beginning of classical Pavlovian conditioning, DA cells react phasically to unconditioned stimuli (US, rewards). After enough conditioning trials, DA cells only react to conditioned stimuli (CS), i.e. stimuli which predict the delivery of a reward. Moreover, if the reward is omitted, DA cells exhibit a pause in firing. This pattern of activation corresponds to the RPE: DA cells respond to unexpected reward events, either positively when more reward than expected is received, or negatively when less reward is delivered. The simplicity of this model has made RPE a successful model of DA activity (but see Vitay and Hamker (2014) for a more detailed model).\nA similar but not identical functional dichotomy as MF/MB opposes deliberative goal-directed behavior and inflexible stimulus-response associations called habits (Dickinson and Balleine, 2002). Goal-directed behavior is sensitive to reward devaluation: if an outcome was previously rewarding but ceases to be (for example, a poisonous product is injected into some food reward, even outside the conditioning phase), goal-directed behavior would quickly learn to avoid that outcome, while habitual behavior will continue to seek for it. Over-training can transform goal-directed behavior into habits (Corbit and Balleine, 2011). Habits are usually considered as a model-free learning behavior, while goal-directed behavior implies the use of a world model. The dual system theory discusses the arbitration mechanisms necessary to coordinate these two learning frameworks (Lee et al., 2014).\nBoth forms of behavior are thought to happen concurrently in the brain, with model-based / goal-directed behavior classically assigned to the prefrontal cortex and the hippocampus and model-free / habitual behavior mapped to the ventral basal ganglia and the dopaminergic system. However, recent results and theories suggest that these two functional systems are largely overlapping and that even dopamine firing might reflect model-based processes (Doll et al., 2012; Miller et al., 2018). It is yet to be understood how these two extreme mechanisms of the RL spectrum might coexist in the brain and be coordinated: successor representations might provide us with additional useful insights into the functioning of the brain."
  },
  {
    "objectID": "post/successor_representations/index.html#successor-representations-in-reinforcement-learning",
    "href": "post/successor_representations/index.html#successor-representations-in-reinforcement-learning",
    "title": "Successor Representations",
    "section": "2 Successor representations in reinforcement learning",
    "text": "2 Successor representations in reinforcement learning\n\n2.1 Main idea\nThe original formulation of successor representations (SR) is actually not recent (Dayan, 1993), but it is subject to a revival since a couple of years with the work of Samuel J. Gershman and colleagues (Gardner et al., 2018; Gershman et al., 2012; Gershman, 2018; Momennejad et al., 2017; Stachenfeld et al., 2017).\nThe SR algorithm learns two quantities:\n\nThe expected immediate reward received after each state:\n\n\n    r(s) = \\mathbb{E}_{\\pi} [r_{t+1} | s_t = s]\n\n\nThe expected discounted future state occupancy (the SR itself):\n\n\n    M(s, s') = \\mathbb{E}_{\\pi} [\\sum_{k=0}^\\infty \\gamma^k \\, \\mathbb{I}(s_{t+k+1} = s') | s_t = s]\n\nI omit here the dependency of r and M on the policy itself in the notation, but it is of course implicitly there.\nThe SR represents the fact that a state s' can be reached after s, with a value decreasing with the temporal gap between the two states: states occurring in rapid succession will have a high SR, very distant states will have a low SR. If s' happens consistently before s, the SR should be 0 (causality principle). This is in principle similar to model-based RL, but without an explicit representation of the transition structure: it only represents how states are temporally correlated, not which action leads to which state.\nThe value of a state s is then defined by:\n\n    V^\\pi(s) = \\sum_{s'} M(s, s') \\, r(s')\n\nThe value of a state s depends on which states s' can be visited after it (following the current policy, implicitly), how far in the future they will happen (discount factor in M(s, s')) and how much reward can be obtained immediately in those states (r(s')). Note that it is merely a rewriting of the definition of the value of a state, with rewards explicitly separated from state visitation and time replaced by succession probabilities:\nV^\\pi(s_t) = \\mathbb{E}_{\\pi} [\\sum_{k=0} \\gamma^k \\, r_{t+k+1}] = \\mathbb{E}_{\\pi} [\\sum_{k=0} r(s_{t+k+1}) \\times (\\gamma^k \\, \\mathbb{I}(s_{t+k+1}))]\nThe SR also obeys a recursive relationship similar to the Bellman equation, as it is based on a discounted sum:\n\n    M(s_t, s') = \\mathbb{I}(s_t = s') + \\gamma \\, M(s_{t+1}, s')\n\nThe discounted probability of arriving in s' after being in s_t is one if we are already in s', and gamma times the discounted probability of arriving in s' after being in the next state s_{t+1} otherwise.\nThis recursive relationship implies that we are going to be able to estimate the SR M(s, s') using a sensory prediction error (SPE) similar to the TD RPE (Gershman et al., 2012):\n\n    \\delta^\\text{SR}_t = \\mathbb{I}(s_t = s') + \\gamma \\, M(s_{t+1}, s') - M(s_t, s')\n\n\n    \\Delta M(s_t, s') = \\alpha \\, \\delta^\\text{SR}_t\n\nThe SPE states that the expected occupancy for states that are visited more frequently than expected (positive sensory prediction error) should be increased, while the expected occupancy for states that are visited less frequently than expected (negative sensory prediction error) should be decreased. In short: is arriving in this new state surprising? It should be noted that the SPE is defined over all possible successor states s', so the SPE is actually a vector.\nWe can already observe that SR is a trade-off between MF and MB methods. A change in the reward distribution can be quickly tracked by SR algorithms, as the immediate reward r(s) can be updated with:\n\n    \\Delta r(s) = \\alpha \\, (r_{t+1} - r(s))\n\nHowever, the SR M(s, s') uses other estimates for its update (bootstrapping), so changes in the transition structure may take more time to propagate to all state-state discounted occupancies (Gershman, 2018).\n\n\n2.2 Linear function approximation\nBefore looking at the biological plausibility of this algorithm, we need to deal with the curse of dimensionality. The SR M(s, s') is a matrix associating each state of the system to all other states (size |\\mathcal{S}| \\times |\\mathcal{S}|). This is of course impracticable for most problems and we need to rely on function approximation. The simplest solution is to represent each state s by a set of d features [f_i(s)]_{i=1}^d. Each feature can for example be the presence of an object in the scene, some encoding of the position of the agent in the world, etc. The SR for a state s only needs to predict the expected discounted probability that a feature f_j will be observed in the future, not the complete state representation. This should ensure generalization across states, as only the presence of relevant features is needed. The SR can be linearly approximated by:\n\n    M_j(s) = \\sum_{i=1}^d w_{i, j} \\, f_i(s)\n\nThe expected discounted probability of observing the feature f_j in the future is defined as a weighted sum of the features of the state s. The value of a state is now defined as:\n\n    V^\\pi(s) = \\sum_{j=1}^d M_j(s) \\, r(f_j) = \\sum_{j=1}^d r(f_j) \\, \\sum_{i=1}^d w_{i, j} \\, f_i(s)\n\nwhere r(f_j) is the expected immediate reward when observing the feature f_j, what can be easily tracked as before. Computing the value of a state based on the SR now involves a double sum over a d \\times d matrix, d being the number of features, what should generally be much more tractable than over the total number of states squared.\nAs we use linear approximation, the learning rule for the weights w_{i, j} becomes linearly dependent on the SPE:\n\n    \\delta^\\text{SR}_t(f_j) = f_j(s_t) + \\gamma \\, M_j(s_{t+1}) - M_j(s)\n\n\n    \\Delta w_{i, j} = \\alpha \\, \\delta^\\text{SR}_t(f_j) \\, f_i(s_t)\n\nThe SPE tells us how surprising is each feature f_j when being in the state s_t. This explains the term sensory prediction error: we are now not learning based on how surprising rewards are anymore, but on how surprising the sensory features of the outcome are. Did I expect that door to open at some point? Should this event happen soon? What kind of outcome is likely to happen? As the SPE is now a vector for all sensory features, we see why successor representation have a great potential: instead of a single scalar RPE dealing only with reward magnitudes, we now can learn from very diverse representations describing the various relevant dimensions of the task. It can then deal with different rewards: food and monetary rewards are treated the same by RPEs, while we can distinguish them with SPEs.\nThe main potential problem is of course to extract the relevant features for the task, either by hand-engineering them or through learning (one could work in the latent space of a variational autoencoder, for example). Feature-based state representations still have to be Markovian for SR to work. It is also possible to use non-linear function approximators such as deep networks Machado et al. (2018), but this is out of the scope of this post.\n\n\n2.3 Successor representations of actions\nThe previous sections focused on the successor representation of states to obtain the value function V^\\pi(s). The same idea can be applied to state-action pairs and their Q^\\pi(s, a) values. The Q-value of a state action pair can be defined as:\n\n    Q^\\pi(s, a) = \\sum_{s', a'} M(s, a, s', a') \\, r(s', a')\n\nwhere r(s', a') is the expected immediate reward obtained after (s', a') and M(s, a, s', a') is the SR between the pairs (s, a) and (s', a') as in Momennejad et al. (2017). Ducarouge and Sigaud (2017) use a SR representation between a state-action pair (s, a) and a successor state s':\n\n    Q^\\pi(s, a) = \\sum_{s'} M(s, a, s') \\, r(s')\n\nIn both cases, the SR can be learned using a sensory prediction error, such as:\n\n    \\delta^\\text{SR}_{s_t, a_t} = \\mathbb{I}(s_t = s') + \\gamma \\, M(s_{t+1}, a_{t+1}, s') - M(s_t, a_t, s')\n\nNote that eligibility traces can be used in SR learning as easily as in TD methods."
  },
  {
    "objectID": "post/successor_representations/index.html#successor-representations-in-neuroscience",
    "href": "post/successor_representations/index.html#successor-representations-in-neuroscience",
    "title": "Successor Representations",
    "section": "3 Successor representations in neuroscience",
    "text": "3 Successor representations in neuroscience\n\n3.1 Human goal-directed behavior\nSo great, we now have a third form of reinforcement learning. Could it be the missing theory to explain human reinforcement learning and the dichotomy goal-directed behavior / habits?\nMomennejad et al. (2017) designed a two-steps sequential learning task with reward and transition revaluations. In the first learning phase, the subjects are presented with sequences of images (the states) and obtain different rewards (Fig. 1). The sequence 1 \\rightarrow 3 \\rightarrow 5 is rewarded with 10 dollars while the sequence 2 \\rightarrow 4 \\rightarrow 6 is rewarded with 1 dollar only. Successful learning is tested by asking the participant whether he/she prefers the states 1 or 2 (the answer is obviously 1).\n\n\n\nTwo-steps sequential learning task of Momennejad et al. (2017).\n\n\nIn the reward revaluation task, the transitions 3 \\rightarrow 5 and 4 \\rightarrow 6 are experienced again in the re-learning phase, but this time with reversed rewards (1 and 10 dollars respectively). In the transition revaluation task, the transitions 3 \\rightarrow 6 and 4 \\rightarrow 5 are now experienced, but the states 5 and 6 still receive the same amount of reward. The preference for 1 or 2 is again tested at the end of the re-learning phase (2 should now be preferred in both tasks) and a revaluation score is computed (how much the subject changes his preference between the two phases).\nWhat would the different ML methods predict?\n\nModel-free methods would not change their preference in both conditions. The value of the 3 \\rightarrow 5 and 4 \\rightarrow 6 transitions (reward revaluation) or 3 \\rightarrow 6 and 4 \\rightarrow 5 (transition revaluation) would change during the re-learning phase, but the transitions 1 \\rightarrow 3 and 2 \\rightarrow 4 are never experienced again, so the value of the states 1 and 2 can only stay the same, even with eligibility traces.\nModel-based methods would change their preference in both conditions. The reward and transition probabilities would both be re-learned completely to reflect the change, so the new value of 1 and 2 can be computed correctly using dynamic programming.\nSuccessor representation methods would adapt to the reward revaluation (r(s) will quickly fit the new reward distribution for the states 5 and 6), but not to the transition revaluation: 6 is never a successor state of 1 in the re-learning phase, so the SR matrix will not be updated for the states 1 and 2.\n\nWe have three different mechanisms with testable predictions on these two tasks: the human experiments should tell us which method is the best model of human RL. Well… Not really.\n\n\n\nRevaluation score in the reward (red) and transition (blue) revaluation conditions for the model-free (MF), model-based (MB), successor representation (SR) and human data as reported in Momennejad et al. (2017).\n\n\nHuman participants show a revaluation behavior in the two conditions (reward and transition) somehow in between the model-based and successor representation algorithms. The difference between the reward and transition conditions is statistically significant, so unlike MB, but not as dramatic as for SR. The authors propose a hybrid SR-MB model, linearly combining the outputs of the MB and SR algorithms, and fit it to the human data to obtain a satisfying match. A second task requiring the model to actually take actions confirms this observation.\nIt is hard to conclude anything definitive from this model and the somehow artificial fit to the data. Reward revaluation was the typical test to distinguish between MB and MF processes, or between goal-directed behavior and habits. This paper suggests that transition revaluation (and policy revaluation, investigated in the second experiment) might allow distinguishing between MB and SR mechanisms, supporting the existence of SR mechanisms in the brain. How MB and SR might interact in the brain and whether there is an arbitration mechanism between the two is still an open issue. Russek et al. (2017) has a very interesting discussion on the link between MF and MB processes in the brain, based on different versions of the SR.\n\n\n3.2 Neural substrates of successor representations\nIn addition to describing human behavior at the functional level, the SR might also allow to better understand the computations made by the areas involved in goal-directed behavior, in particular the prefrontal cortex, the basal ganglia, the dopaminergic system, and the hippocampus. The key idea of Gershman and colleagues is that the SR M(s, s') might be encoded in the place cells of the hippocampus (Stachenfeld et al., 2017), which are known to be critical for reward-based navigation. The sensory prediction error (SPE \\delta^\\text{SR}_t) might be encoded in the activation of the dopaminergic cells in VTA (or in a fronto-striatal network), driving learning of the SR in the hippocampus (Gardner et al., 2018), while the value of a state V^\\pi(s) = \\sum_{s'} M(s, s') \\, r(s') could be computed either in the prefrontal cortex (ventromedial or orbitofrontal) or in the ventral striatum (nucleus accumbens in rats), ultimately allowing action selection in the dorsal BG.\n\n3.2.1 Dopamine as a SPE\nThe most striking prediction of the SR hypothesis is that the SPE is a vector of prediction errors, with one element per state (in the original formulation) or per reward feature (using linear function approximation, section 2.2). This contrasts with the classical RPE formulation, where dopaminergic activation is a single scalar signal driving reinforcement learning in the BG and prefrontal cortex (Schultz, 1998). Although this would certainly be an advantage in terms of functionality and flexible learning, it remains to be shown whether VTA actually encodes such a feature-specific signal.\nNeurons in VTA have a rather uniform response to rewards or reward-predicting cues, encoding mostly the value of the outcome regardless its sensory features, except for those projecting to the tail of the striatum which mostly respond to threats and punishments (Watabe-Uchida and Uchida, 2019). The current state of knowledge seems to rule out VTA as a direct source of SPE signals.\nInterestingly, Oemisch et al. (2019) showed that feature-specific prediction errors signals (analogous to the SPE with linear approximation) are detected in the fronto-striatal network including the anterior cingulate area (ACC), dorsolateral prefrontal cortex (dlPFC), dorsal striatum and ventral striatum (VS) / nucleus accumbens (NAcc). These SPE-like signals appear shortly after non-specific RPE signals, first in ACC and then in the rest of the network. This suggests that SPE would actually be the result of a more complex calculation than proposed in the SR hypothesis, involving a network of interconnected areas. A detailed neuro-computational model of this network still has to be proposed.\n\n\n3.2.2 Hippocampus as a predictive map\nAnother interesting prediction of the SR hypothesis is that the hippocampus might be the site where the SR matrix is represented (Stachenfeld et al., 2017). In navigation tasks, the so-called place cells in the hippocampus exhibit roughly circular receptive fields centered on different locations in the environment (O’Keefe and Nadel, 1978). Altogether, place cells are thought to provide a sparse code of the animal’s location. Strikingly, place fields change with the environment: moving the animal from a circular to a rectangular environment, or introducing barriers, modifies the distribution of place fields. Additionally, grid cells in the entorhinal cortex (reciprocally connected to the hippocampus) show a hexagonal grid pattern of receptive fields, i.e. a single grid cell responds for several positions of the animal inside the environment (Hafting et al., 2005). Grid cells’ receptive fields also depend on the environment and have been shown to depend on place cells, not the other way around. The mechanism behind the flexibility of place and grid fields is still to be understood.\nStachenfeld et al. (2017) propose that place cells actually encode the SR M(s, s') between the current location s and their preferred location s', rather than simply an Euclidian distance between s and s' as classically used in hippocampal models. Because of the discount rate in the SR and its dependency on the animal’s policy, place fields are then roughly circular (exponentially decreasing) in an open environment, where the animal can theoretically reach any neighboring location from its current position. When constraints are added to the environment, such as walls and barriers, certain transitions are not possible anymore, which will modify the shape of the place fields. This fits with experimental observations, contrary to most models of place field formation using Gaussian receptive fields around fixed locations. Additionally, the SR hypothesis is in agreement with the observation that rewarded locations are represented by a higher number of place cells, as the animal spends more time around them.\n\n\n\nPlace field on a linear track with an obstacle at x=1, using a Euclidian model (left) and the SR hypothesis (right). Adapted from Fig. 2 of Stachenfeld et al. (2017).\n\n\nFig. 3 illustrates this prediction: if a rat is placed on a linear track with an obstacle, the place cell whose RF is centered on the obstacle would react identically on both sides of the obstacle using a Euclidian model, while it would only respond on the side it has explored using the SR. When the rat is put on the other side, the SRs would initially be 0 for that cell (but would grow with more exploration).\nStachenfeld et al. (2017) also propose a mechanism for grid cell formation in the entorhinal cortex. Grid cells are understood as a low-dimensional eigendecomposition of the SR place cells (dimensionality reduction, as in principal component analysis). This allows to explain why grid cells change in different environments (circular, rectangular or triangular), as experimentally observed. They also propose a mechanism for sub-goal formation using grid cells, but using the normalized min-cut algorithm, so quite far from being biologically realistic."
  },
  {
    "objectID": "post/successor_representations/index.html#discussion",
    "href": "post/successor_representations/index.html#discussion",
    "title": "Successor Representations",
    "section": "4 Discussion",
    "text": "4 Discussion\nSuccessor representations are an interesting trade-off between model-free and model-based RL algorithms, explicitly separating state transitions from reward estimation. It allows reacting quickly to distal reward changes without the computational burden of completely model-based planning. Deep RL variants of SR (Kulkarni et al., 2016) obtain satisfying results on classical RL tasks such as Atari games and simulated robots, but are still outperformed by modern model-free algorithms. Similar to human behavior, hybrid architectures using both SR and MF methods might be able to combine the optimality of MF methods with the flexibility of the SR.\nAt the neuroscientific level, the SR hypothesis raises a lot of interesting questions, especially regarding the interplay between the prefrontal cortex, the hippocampus, and the basal ganglia during goal-directed behavior. Here are just a few aspects that need to be investigated both experimentally and theoretically:\n\nWhat is the relationship between the RPE and the SPE? Does VTA compute the SPE (still to be proven) and send it directly to the hippocampus through dopaminergic projections? Or does the RPE VTA somehow “train” ACC and PFC to compute the SPE, what is then sent to the hippocampus to update the SR representation? How?\nHow does the hippocampus learn from SPE signals? The SR hypothesis still has to be linked with evidence on plasticity in the hippocampus.\nIf dopamine does not carry the SPE, what is the role of the dopaminergic innervation of the hippocampus? The SR representation is in principle independent from rewards (except that animals may spend more time around reward location).\nHow is the value of a state / action computed based on the SR representation in the hippocampus? Do sharp wave ripples (SWR, also called forward/inverse replays) actually sample the SR matrix (a list of achievable states from the current one), what is then integrated elsewhere (ventral striatum?) to guide behavior?"
  }
]